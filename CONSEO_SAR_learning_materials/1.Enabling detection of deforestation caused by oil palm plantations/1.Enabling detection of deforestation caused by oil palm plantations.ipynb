{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aafd21e-a727-4933-9627-ec43e30121fb",
   "metadata": {},
   "source": [
    "# 1. Enable ALOS-2/PALSAR-2 data processing to detect extension of oil palm plantations\n",
    "\n",
    "First, install the packages required for data processing.If Anaconda is installed with administrative privileges, Jupyter Notebook must be run with administrative privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b9cc2d-d8ef-46ab-a5ac-5c0beefee141",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge rasterio matplotlib gdal geopandas -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e21cce",
   "metadata": {},
   "source": [
    "In this section, the following procedure illustrates the observation of oil palm plantation expansion and deforestation using ALOS-2/PALSAR2 data.\n",
    "\n",
    "- Understand the relationship between features in multi-polarization (HH/HV) color composite imagery and land cover/land use seen in high-resolution imagery such as Google Earth.\n",
    "- Practice Change Vector Analysis, a method for analyzing land cover and land use changes using two periods of observation data.\n",
    "\n",
    "### Key learning objectives:\n",
    "- 1.1 Visualization of ALOS-2/PALSAR-2 data using Python\n",
    "- 1.2 Change detection analysis based on analysis of 2-time period data\n",
    "- 1.3 Advantages and Uses of this Exercise Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386bbae-8ded-4001-8303-07ede4f232f7",
   "metadata": {},
   "source": [
    "## 1.1. Visualization of ALOS-2/PALSAR-2 data using Python\n",
    "\n",
    "### 1.1.1. Visualizing PALSAR-2 data of a tropical forest with oil palm plantations\n",
    "\n",
    "- Create a color composite image with several years of HH and HV data.\n",
    "- Understand how to show the image characteristics of typical land cover and compare and interpret them with high-resolution images from Google.\n",
    "\n",
    "#### 1.1.1.1. Color composite of multi-polarization SAR data HH and HV\n",
    "- In this exercise, you will read and visualize ALOS-2 image data using Python.\n",
    "- For analysis of oil palm plantation expansion and deforestation, the ALOS-2 annual composite data is useful.\n",
    "- This exercise will be available on the JAXA ALOS-2 portal.[Global PALSAR-2/PALSAR/JERS-1 mosaic and forest/non-forest maps](https://www.eorc.jaxa.jp/ALOS/jp/dataset/fnf_j.htm)\n",
    "\n",
    "![DownloadingALOS-2Data.png](download_alos2.png)\n",
    "\n",
    "Note, For this exercise, we have prepared the data in advance to save time. 1-demo_data.zip is used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab90b71",
   "metadata": {},
   "source": [
    "**Data downloading**\n",
    "- ALOS-2 data can be obtained from the Japan Aerospace Exploration Agency (JAXA).\n",
    "- Ensure the data is in GeoTIFF format for compatibility with the provided code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab2eac-c863-4102-ab9f-cd7fe00b67ca",
   "metadata": {},
   "source": [
    "For this hands-on exercise, we have prepared the data to save you time. What you need to do is download the data from our ownCloud server to your working directory to practice the next steps in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dcabe8-06f8-4db5-9c7c-421f4a4c932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --content-disposition \"https://owncloud.glodal-inc.net/owncloud/index.php/s/wETRZGKkCvWkHC0/download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526d8be-8520-4117-8461-ce71e4fa441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c103b-e101-4345-880e-60d6c74b6c1c",
   "metadata": {},
   "source": [
    "After downloading, you can unzip the file using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a9f88-356e-4db9-8492-f003c1890acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip IND_ALOS2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1285767-418e-4a8c-ba00-e08eda136f49",
   "metadata": {},
   "source": [
    "Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl --output 1-demo_data.zip http://owncloud.glodal-inc.net/owncloud/index.php/s/uKogtY6XPfokBVN/download\n",
    "import shutil, os\n",
    "os.makedirs('1-demo_data', exist_ok=True)\n",
    "shutil.unpack_archive(\"1-demo_data.zip\", \"1-demo_data\")\n",
    "os.chdir('1-demo_data')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee40766f-8a43-4e8b-9b48-e177fbb7bfd6",
   "metadata": {},
   "source": [
    "##### Creation of RGB composite image\n",
    "\n",
    "- Creating a temporal RGB composite image iuseful for visualizingze differences between multiple SAR images. Since we are working with ALOS-2 images, a common approach is to assign different bands or time-stamped images to the RGB channels.\n",
    "\n",
    "- You can create a RGB composite by combining the two images into the red, green, and blue channels. \n",
    "\n",
    "- Now, let us visualize the SAR images. We will create color composites using HH and HV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc00adb-b4d5-4cf6-b608-0f4b18d0ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterio matplotlib gdal geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2264eeee-2f12-4f37-99f6-6188056ae945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd9a66d",
   "metadata": {},
   "source": [
    "Let's look at the HH and HV images respectively before color compositing. We deal with annual composite data for the years 2007 and 2010. Specify a file name in rasterio and load the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ff0a05-6bc8-4021-a274-712e5da01f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# Load ALOS-2 2007 \n",
    "with rasterio.open('Alos_2_2007_HH.tif') as src:\n",
    "    hh_2007 = src.read(1)\n",
    "with rasterio.open('Alos_2_2007_HV.tif') as src:\n",
    "    hv_2007 = src.read(1)\n",
    "    \n",
    "# Load ALOS-2 2010 \n",
    "with rasterio.open('Alos_2_2010_HH.tif') as src:\n",
    "    hh_2010 = src.read(1)\n",
    "with rasterio.open('Alos_2_2010_HV.tif') as src:\n",
    "    hv_2010 = src.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7301b6",
   "metadata": {},
   "source": [
    "Take a look at each of these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170afb3-09c9-42c3-9fd4-23a0e47b0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data and titles for plots\n",
    "data = [\n",
    "    (hh_2007, \"2007 HH\"),\n",
    "    (hv_2007, \"2007 HV\"),\n",
    "    (hh_2010, \"2010 HH\"),\n",
    "    (hv_2010, \"2010 HV\"),\n",
    "]\n",
    "\n",
    "# Create a 2x2 plot layout\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 10))\n",
    "\n",
    "# Loop through axes and data to plot\n",
    "for ax, (image, title) in zip(axs.flat, data):\n",
    "    img = ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(title)\n",
    "    fig.colorbar(img, ax=ax, orientation='vertical', label='Intensity')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468f41c5",
   "metadata": {},
   "source": [
    "A grayscale image is displayed; assign HH to the red channel and HV to the green and blue channels to create a composite image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3939e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Stack images into RGB channels: HH_t1 as Red, HV_t2 as Green, HH_t3 as Blue\n",
    "rgb_composite_2007 = np.dstack((hh_2007, hv_2007, hv_2007))\n",
    "rgb_composite_2010 = np.dstack((hh_2010, hv_2010, hv_2010))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d296aa-659b-455a-951d-4d2cbeaa9d13",
   "metadata": {},
   "source": [
    "Displays the created composite image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a72250-a41e-40a4-ac21-16ec5a586284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize 2007 composite\n",
    "rgb_composite_2007 = (rgb_composite_2007 - np.min(rgb_composite_2007)) / (np.max(rgb_composite_2007) - np.min(rgb_composite_2007))\n",
    "\n",
    "# Normalize 2010 composite\n",
    "rgb_composite_2010 = (rgb_composite_2010 - np.min(rgb_composite_2010)) / (np.max(rgb_composite_2010) - np.min(rgb_composite_2010))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Plot 2007 composite\n",
    "im1 = ax1.imshow(rgb_composite_2007)\n",
    "ax1.set_title(\"2007 Color Composite of HH and HV Images\")\n",
    "# Plot 2010 composite\n",
    "im2 = ax2.imshow(rgb_composite_2010)\n",
    "ax2.set_title(\"2010 Color Composite of HH and HV Images\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c6390-e310-4fa4-a71d-e8d8f2e6f3b2",
   "metadata": {},
   "source": [
    "The overall darkness makes interpretation difficult. Adjust the contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6efbe-6939-4dbe-b726-285e841482b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to enhance the RGB composite\n",
    "def enhance_composite(rgb_composite, gamma=0.5):\n",
    "    # Apply gamma correction\n",
    "    rgb_composite_gamma = np.zeros_like(rgb_composite)\n",
    "    for i in range(3): \n",
    "        rgb_composite_gamma[:, :, i] = np.power(rgb_composite[:, :, i], gamma)\n",
    "\n",
    "    # Calculate percentiles for contrast stretching\n",
    "    p2_r, p98_r = np.percentile(rgb_composite_gamma[:, :, 0], (5, 95))\n",
    "    p2_g, p98_g = np.percentile(rgb_composite_gamma[:, :, 1], (5, 95))\n",
    "    p2_b, p98_b = np.percentile(rgb_composite_gamma[:, :, 2], (5, 95))\n",
    "\n",
    "    # Perform contrast stretching\n",
    "    r_stretched = np.clip((rgb_composite_gamma[:, :, 0] - p2_r) / (p98_r - p2_r), 0, 1)\n",
    "    g_stretched = np.clip((rgb_composite_gamma[:, :, 1] - p2_g) / (p98_g - p2_g), 0, 1)\n",
    "    b_stretched = np.clip((rgb_composite_gamma[:, :, 2] - p2_b) / (p98_b - p2_b), 0, 1)\n",
    "\n",
    "    # Combine stretched channels back into an RGB image\n",
    "    return np.dstack((r_stretched, g_stretched, b_stretched))\n",
    "\n",
    "# Enhance both 2007 and 2010 composites\n",
    "rgb_composite_enhanced_2007 = enhance_composite(rgb_composite_2007)\n",
    "rgb_composite_enhanced_2010 = enhance_composite(rgb_composite_2010)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# Plot 2007 enhanced composite\n",
    "im1 = ax1.imshow(rgb_composite_enhanced_2007)\n",
    "ax1.set_title(\"2007 Enhanced color composite of HH and HV images\")\n",
    "# Plot 2010 enhanced composite\n",
    "im2 = ax2.imshow(rgb_composite_enhanced_2010)\n",
    "ax2.set_title(\"2010 Enhanced color composite of HH and HV images\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913d767",
   "metadata": {},
   "source": [
    "Color compositing and contrast adjustment allow interpretation of land cover and land use in the target area. The red region indicates greater scattering of HH compared to HV, and the blue-white region indicates greater scattering of HV compared to HH."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8d7f0",
   "metadata": {},
   "source": [
    "#### 1.1.1.2. Example of typical land cover interpretation\n",
    "\n",
    "Land cover can be interpreted from image patterns in ALOS-2/PALSAR-2 color composite images.[Basic principles are explained in the linked explanation„ÄåPolarization and Scattering Mechanisms„Äçfor more information.](https://www.earthdata.nasa.gov/learn/earth-observation-data-basics/sar).Interpretation of image patterns can be used to determine the distribution of land use and land cover. An example of interpretation is shown below.\n",
    "\n",
    "In this exercise, The blue-white area represents the forest, Red areas are sparse vegetation,We note in particular that it represents an oil palm plantation.\n",
    "\n",
    "![](hhhv_des.png)\n",
    "\n",
    "#### 1.1.1.3. Analysis of oil palm plantation expansion using color composite images of time series data\n",
    "\n",
    "Visualize the annual data for even more periods here, Let's analyze the dynamics of oil palm plantations in this area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d61f29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_composite = list()\n",
    "rgb_composite_enhanced = list()\n",
    "\n",
    "for YYYY in [2007, 2010, 2015, 2020]:\n",
    "    hh = rasterio.open('Alos_2_' + str(YYYY) + '_HH.tif').read(1)\n",
    "    hv = rasterio.open('Alos_2_' + str(YYYY) + '_HV.tif').read(1)\n",
    "    rgb_composite_enhanced.append(enhance_composite(np.dstack((hh, hv, hv))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e6a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "YYYY = [2007, 2010, 2015, 2020]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, len(YYYY), figsize=(12, 24))\n",
    "\n",
    "# Iterate over axes and data to plot\n",
    "for ax, year, image in zip(axes, YYYY, rgb_composite_enhanced):\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(str(year))\n",
    "    # Remove axis labels\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6cf8f4",
   "metadata": {},
   "source": [
    "Let's take a closer look at the area slightly north of the center of the western edge of the region.\n",
    "\n",
    "|    Vegetation to oil palm plantation          | 2007                                  | 2010                | 2015                   | 2020 |\n",
    "|-------------------|----------------------------------|-------------------------------|---------------------------------|-----------------------------------------|\n",
    "|**ALOS-2/PALSAR-2 composite image   (R:HH G:HV B:HV)**        | ![07rgb.png](07rgb.png) | ![10rgb.png](10rgb.png) |![15rgb.png](15rgb.png) | ![20rgb.png](20rgb.png) |\n",
    "| **Satellite photo by Google Earth**       | ![07gg.png](07gg.png)      | ![10gg.png](10gg.png) | ![15gg.png](15gg.png) | ![20gg.png](20gg.png) |\n",
    "\n",
    "Around the center of this regionÔºàlatitude 1.26, longitude around 100.10Ôºâon Google Earth.**High-resolution images from December 2013** is included in the collection, so take a look at it,You can see that palm palms are neatly arranged in rows. It can be inferred that the transition of the area that was forest cover in 2007 (blue-white area) was developed as an oil palm plantation over a period of more than 10 years.\n",
    "\n",
    "![image.png](oilpalm_1.png)\n",
    "\n",
    "Also, for the black region in 2010 (small scatter for both HV/HH; latitude 1.273, longitude around 100.094) region,**High-resolution images from June 2013** is recorded, so the area is partially left after it has been reclaimed, and oil palms can be seen scattered throughout the area. Given that it takes several years for oil palm to grow to the point where it can produce palm oil, the PALSAR-2 data is expected to capture the transition of oil palm growth.\n",
    "\n",
    "![image.png](oilpalm_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fed4f",
   "metadata": {},
   "source": [
    "#### Memory management\n",
    "\n",
    "Free memory of unnecessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46fa5476",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rgb_composite_enhanced, hv, hh, rgb_composite_2007, rgb_composite_2010, rgb_composite_enhanced_2007, rgb_composite_enhanced_2010 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501b17a",
   "metadata": {},
   "source": [
    "## 1.2. Change detection analysis based on analysis of 2-time period data\n",
    "\n",
    "In this section,By analyzing the HH/HV scattering intensities during the two periods with Change Vector Analysis, the procedure for detecting and analyzing changes will be practiced. In the previous section, we analyzed land cover and land use changes by comparing color tones and patterns in color composite images from year to year.\n",
    "\n",
    "Change vector analysisis a method used to analyze changes in 2D data points and is an effective method for analyzing HH/HV changes in PALSAR-2. In this section, we will deepen our understanding of the procedures and interpretations by analyzing the 2007 and 2010 annual composite data.[Reference 1](https://web.pdx.edu/~nauna/week5.pdf), [Reference 2](https://www.isprs.org/proceedings/xxxiv/part1/paper/00014.pdf)\n",
    "\n",
    "### 1.2.1. Conversion from DN values to backscatter coefficients\n",
    "\n",
    "In the previous section, the pixel valueÔºàDN; digital numberÔºâwas used for visualization as is, but for rigorous data analysis, it is desirable to convert the pixel values ‚Äã‚Äãinto backscattering coefficients. The conversion is done using the following formula:\n",
    "\n",
    "$$ \\gamma^{0} = 10 log_{10} <DN^2> + CF $$\n",
    "\n",
    "Note that, <> represents averaging for noise reduction and -83.0 dB is used for CF. [Global 25m Resolution PALSAR-2/PALSAR Mosaic (Ver. 2.4.0) Dataset Instructions](https://www.eorc.jaxa.jp/ALOS/jp/dataset/pdf/DatasetDescription_PALSAR2_Mosaic_ver240_ja.pdf). A coding example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b069dfe2-34b4-453f-bdb3-33668565ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_ima(image):\n",
    "    return 10 * np.log10(image ** 2) - 83.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f2ef827-e3be-40b9-be25-6ccabfff0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ima_cal(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        original = src.read(1).astype('float32')\n",
    "        calibrated = calibrate_ima(original)\n",
    "    return original, calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e757c2bf-295d-499b-8cb5-a765bafb17b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_2007_raw, hh_2007_cal = ima_cal(hh_2007_path)\n",
    "hh_2010_raw, hh_2010_cal = ima_cal(hh_2010_path)\n",
    "hv_2007_raw, hv_2007_cal = ima_cal(hv_2007_path)\n",
    "hv_2010_raw, hv_2010_cal = ima_cal(hv_2010_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd442e42-5786-43e8-82cc-577468582fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calibrate_ima(image):\n",
    "    return 10 * np.log10(image ** 2) - 83.0\n",
    "\n",
    "def ima_cal(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        original = src.read(1).astype('float32')\n",
    "        calibrated = calibrate_ima(original)\n",
    "    return original, calibrated\n",
    "\n",
    "hh_2007_path = \"Alos_2_2007_HH.tif\" \n",
    "hh_2010_path = \"Alos_2_2010_HH.tif\"\n",
    "hv_2007_path = \"Alos_2_2007_HV.tif\"\n",
    "hv_2010_path = \"Alos_2_2010_HV.tif\"\n",
    "\n",
    "hh_2007_raw, hh_2007_cal = ima_cal(hh_2007_path)\n",
    "hh_2010_raw, hh_2010_cal = ima_cal(hh_2010_path)\n",
    "hv_2007_raw, hv_2007_cal = ima_cal(hv_2007_path)\n",
    "hv_2010_raw, hv_2010_cal = ima_cal(hv_2010_path)\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(12, 16))\n",
    "\n",
    "axs[0, 0].imshow(hh_2007_raw, cmap='gray')\n",
    "axs[0, 0].set_title('Year 2007 HH (Original)')\n",
    "axs[0, 1].imshow(hh_2007_cal, cmap='gray')\n",
    "axs[0, 1].set_title('Year 2007 HH (Calibrated)')\n",
    "\n",
    "axs[1, 0].imshow(hh_2010_raw, cmap='gray')\n",
    "axs[1, 0].set_title('Year 2010 HH (Original)')\n",
    "axs[1, 1].imshow(hh_2010_cal, cmap='gray')\n",
    "axs[1, 1].set_title('Year 2010 HH (Calibrated)')\n",
    "\n",
    "axs[2, 0].imshow(hv_2007_raw, cmap='gray')\n",
    "axs[2, 0].set_title('Year 2007 HV (Original)')\n",
    "axs[2, 1].imshow(hv_2007_cal, cmap='gray')\n",
    "axs[2, 1].set_title('Year 2007 HV (Calibrated)')\n",
    "\n",
    "axs[3, 0].imshow(hv_2010_raw, cmap='gray')\n",
    "axs[3, 0].set_title('Year 2010 HV (Original)')\n",
    "axs[3, 1].imshow(hv_2010_cal, cmap='gray')\n",
    "axs[3, 1].set_title('Year 2010 HV (Calibrated)')\n",
    "\n",
    "for i in range(4):\n",
    "    fig.colorbar(axs[i, 0].imshow(hh_2007_raw, cmap='gray'), ax=axs[i, 0], orientation='vertical', label='DN')\n",
    "    fig.colorbar(axs[i, 1].imshow(hh_2007_cal, cmap='gray'), ax=axs[i, 1], orientation='vertical', label='Calibrated dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba915c6",
   "metadata": {},
   "source": [
    "##### (Optional) If the conversion process takes a long time\n",
    "\n",
    "The above process may take some time depending on the performance of your PC. In that case, stop the process and execute the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aeedfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('2007HHcalibrated5_image.tif') as src:\n",
    "    hh_2007_cal = src.read(1)\n",
    "with rasterio.open('2007HVcalibrated5_image.tif') as src:\n",
    "    hv_2007_cal = src.read(1)\n",
    "    \n",
    "# Load ALOS-2 2010\n",
    "with rasterio.open('2010HHcalibrated5_image.tif') as src:\n",
    "    hh_2010_cal = src.read(1)\n",
    "with rasterio.open('2010HVcalibrated5_image.tif') as src:\n",
    "    hv_2010_cal = src.read(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f7c56-08e0-4395-ae89-d412b3f31201",
   "metadata": {},
   "source": [
    "### 1.2.2. HH/HV change analysis\n",
    "\n",
    "Calculate the difference in image data to analyze the change from 2007 to 2010 for each HH/HV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf2eda-f28d-404a-982d-5c50aa6e5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_bandhv_cal = hv_2010_cal - hv_2007_cal\n",
    "delta_bandhh_cal = hh_2010_cal - hh_2007_cal\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 16))\n",
    "\n",
    "axs[0].imshow(delta_bandhv_cal, cmap='gray')\n",
    "axs[0].set_title('HV change (2010 - 2007)')\n",
    "axs[1].imshow(delta_bandhh_cal, cmap='gray')\n",
    "axs[1].set_title('HH change (2010 - 2007)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e6f37e",
   "metadata": {},
   "source": [
    "Darker areas of pixel brightness represent a decrease, Bright areas indicate an increase. A decrease in HV indicates a decrease in volume scattering,It is believed that the forest has been cut down. The pixel values in this difference image usually follow a normal distribution, Approximately 2.5% on each side was considered a significant change, The classification of $ \\mu \\pm 2 * \\sigma $ as the threshold can be used to detect changes.This procedure will be implemented with a different indicator, as it will be practiced in another indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7c7a2",
   "metadata": {},
   "source": [
    "### 1.2.3. Change vector analysis (CVA) Data analysis\n",
    "\n",
    "The changes that appear in the difference image calculated in the previous section can be expressed as vectors in the two-dimensional space of HH/HV pairs for each pixel.The figure below shows an example where HV has decreased significantly while HH has decreased slightly. The following code cell calculates the length of the change vector at each pixel, expressed as magnitude, and the direction as angle.\n",
    "\n",
    "![image.png](HHHV.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a08ec68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude = np.sqrt(delta_bandhv_cal**2 + delta_bandhh_cal**2)\n",
    "angle = np.arctan2(delta_bandhv_cal, delta_bandhh_cal) #Radians: When using trigonometric functions like arctan or atan2, the default output is often in radians, where 00 to 2ùúã2œÄ radians (approximately 00 to 6.286.28) covers the full circular range of angles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a8687d",
   "metadata": {},
   "source": [
    "Visualize the calculation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5f144-f1b4-409f-924c-29586db5dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "norm_magnitude = mcolors.Normalize(vmin=0, vmax=10)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "im1 = axs[0].imshow(magnitude, cmap='hsv', norm=norm_magnitude)\n",
    "axs[0].set_title(\"Magnitude of change\")\n",
    "cbar1 = fig.colorbar(im1, ax=axs[0])\n",
    "cbar1.set_label(\"Intensity\")\n",
    "\n",
    "im2 = axs[1].imshow(angle, cmap='hsv')\n",
    "axs[1].set_title(\"Direction (Angle of change)\")\n",
    "cbar2 = fig.colorbar(im2, ax=axs[1])\n",
    "cbar2.set_label(\"Radians\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac645aa6",
   "metadata": {},
   "source": [
    "Several areas with particularly high pixel values appeared in the magnitude image.Since MAGNITUDE generally follows a normal distribution, it seems possible to consider the edges of the distribution as significant changes.Therefore, we use $\\mu + 2 * \\sigma $ as the threshold to extract regions with significant changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e25b4-c809-4c9e-8701-296c296d846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Generate and plot the histogram\n",
    "data = np.random.choice(magnitude.ravel(), size=10000, replace=False)\n",
    "ax.hist(data, bins=100, color='blue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Set plot title and labels\n",
    "ax.set_title('Histogram of Magnitude', fontsize=14)\n",
    "ax.set_xlabel('Magnitude', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ae419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Calculate the threshold for significant changes\n",
    "threshold = np.mean(magnitude) + 2 * np.std(magnitude)\n",
    "significant_change = np.where(magnitude > threshold, 1, 0)\n",
    "\n",
    "# Define a discrete colormap for significant changes\n",
    "cmap = ListedColormap(['black', 'red'])\n",
    "\n",
    "# Create the subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot significant changes\n",
    "im1 = axs[0].imshow(significant_change, cmap=cmap, origin='upper')\n",
    "axs[0].set_title('Significant Changes', fontsize=14)\n",
    "\n",
    "# Add a colorbar for significant changes\n",
    "cbar1 = fig.colorbar(im1, ax=axs[0], ticks=[0, 1])\n",
    "cbar1.ax.set_yticklabels(['No Change', 'Change'])\n",
    "cbar1.set_label('Change', fontsize=12)\n",
    "\n",
    "# Plot direction (angle of change)\n",
    "im2 = axs[1].imshow(angle / 3.14 * 180, cmap='hsv', origin='upper')\n",
    "axs[1].set_title(\"Angle of Change Vector\", fontsize=14)\n",
    "\n",
    "# Add a colorbar for direction\n",
    "cbar2 = fig.colorbar(im2, ax=axs[1])\n",
    "cbar2.set_label(\"Degree\", fontsize=12)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08f27a",
   "metadata": {},
   "source": [
    "### 1.2.4. Analysis of CVA analysis results\n",
    "\n",
    "Ideally, the data should be overlaid using a GIS or similar tool for analysis, but in this exercise, the result images will be compared for analysis.\n",
    "\n",
    "![image.png](magnitude.png)\n",
    "|  Location |   Google Earth satellite image (2007)  |  Google Earth satellite image  (2010)  | Explanation  | \n",
    "| ---- | ---- |---- | ---- |\n",
    "| a |  ![image.png](a1.png) |  ![image.png](a2.png) | Scattering decreased for both HH and HV, but the decrease in HV was more significant, suggesting that forests were loss between 2007 and 2010. |\n",
    "| b |  ![image.png](b1.png)  | ![image.png](b2.png)  | Scattering increased for both HH and HV. It is thought to be a combined effect of deforestation and increased construction. |\n",
    "|c|![image.png](c1.png)|![image.png](b2.png)|same as above|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31fee0",
   "metadata": {},
   "source": [
    "## 1.3. Advantages and Uses of this Exercise Procedure\n",
    "\n",
    "### Why go through  complicated steps when you can find it all on Google Earth?\n",
    "\n",
    "- In this exercise **Fortunately**, the images included are just for reference; for other periods and areas, they are purchased from MAXAR or Airbus.Even archiving costs 3,000-5,000 yen per kilometer, so it is not realistic to use it for large-area analysis such as oil palm plantations.If you want to analyze past transitions, the annual composite data used in this exercise is easy to use and can be used free of charge (Commercial use is also acceptable?).\n",
    "- Processing high-resolution images such as those included in Google Earth requires a lot of computer resources. The analysis procedure demonstrated in this exercise **is efficient and requires only minimal computation**.\n",
    "\n",
    "### Ideas for using the above benefits\n",
    "\n",
    "- Wide-area change detection screening: A system that continuously processes the latest observation data to detect changes and provides automatic notifications, unlike the method used in this exercise, which relies on past data.\n",
    "- Analysis of the management history of oil palm plantations: By analyzing past data,  we can identify when plantations were established, the growth of oil palms, and profile the history of a large number of plantations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
