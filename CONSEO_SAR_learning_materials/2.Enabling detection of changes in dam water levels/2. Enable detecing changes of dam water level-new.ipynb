{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8db6cb-e6e2-4119-b732-ac9d1b83a442",
   "metadata": {},
   "source": [
    "# 2. Dam water level monitoring using ALOS-2/PALSAR-2 observations\n",
    "\n",
    "- This section is designed for learners who are interested in monitor water level of a dam with ALOS-2 - case study of Yamba Dam, Japan.\n",
    "\n",
    "## Learning objectives of this training material\n",
    "\n",
    "- Pre-processing to reduce speckle noise (optional)\n",
    "- Visualization of SAR satellite observation data of Yamba Dam\n",
    "- Change detection of dam operation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857fd2e",
   "metadata": {},
   "source": [
    "### Introduction to ALOS-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff335bb",
   "metadata": {},
   "source": [
    "#### a. (Basic) [Introduction to ALOS-2 data imagery](https://www.eoportal.org/satellite-missions/alos-2#alos-2-advanced-land-observing-satellite-2-sar-mission--daichi-2)\n",
    "\n",
    "This website provides general information about the ALOS-2 (Daichi-2) satellite, their mission and its advanced SAR capabilities for Earth observation and disaster monitoring.\n",
    "Learners wil understand the points below from this content:\n",
    "1. Overview of ALOS-2.\n",
    "2. Mission Capabilities\n",
    "3. Performance Specifications\n",
    "4. Space and Hardware Components\n",
    "5. ALOS-2 (Advanced Land Observing Satellite-2; SAR mission) / Daichi-2\n",
    "6. Spacecraft\n",
    "7. Mission Status\n",
    "8. Sensor Complement \n",
    "9. Ground System\n",
    "\n",
    "#### b. (Basic) [ALOS Data Application (Examples of Researches)](https://www.eorc.jaxa.jp/ALOS/en/gallery/example.htm)\n",
    "\n",
    "NASDA's EORC classifies ALOS data application research areas into the following 12 categories;\n",
    "\n",
    "- PRISM / AVNIR-2: Evaluation of PRISM and AVNIR-2 involves assessing sensor characteristics, image quality, geometric and radiometric calibration and validation, and developing methods for fast and accurate extraction of geo-physical parameters.\n",
    "- PALSAR: Evaluation of PALSAR focuses on assessing sensor characteristics, image quality, geometric and radiometric calibration and validation, along with enhancing analysis methods using microwave scattering and SAR interference.\n",
    "- Digital Elevation Model (DEM) and Mapping\n",
    "- Land Use Monitoring and Land Cover Classification\n",
    "- Disaster Monitoring\n",
    "- Geological Surveying and Mineral Resource Exploration\n",
    "- Terrestrial Ecosystem and Forestry Management\n",
    "- Oceanography and Coastal Zone Related Research\n",
    "- Snow and Ice Related Research\n",
    "- Agriculture Management\n",
    "- Hydrology and Water Resource Management\n",
    "- Application Research using Geographical Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd558e",
   "metadata": {},
   "source": [
    "First, install the packages used in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c569f-e0fc-411f-8cde-cf0530e82b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge numpy matplotlib scikit-image rasterio -y\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e874af-6e26-4870-ab83-aae9bbf827ff",
   "metadata": {},
   "source": [
    "## 2.1. Preparing ALOS-2 data\n",
    "\n",
    "### 2.1.1. Downloading ALOS-2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2577c0-59e1-4b7a-ad81-286c791181d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl --output 2-Yamba.zip \"https://owncloud.glodal-inc.net/owncloud/index.php/s/fORunC9aDo38G5s/download\"\n",
    "\n",
    "import shutil, os\n",
    "shutil.unpack_archive(\"2-Yamba.zip\", \".\")\n",
    "os.chdir('Yamba')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08506ae",
   "metadata": {},
   "source": [
    "### 2.1.2 Preprocessing (speckle noise reduction and DN transform)\n",
    "\n",
    "#### Speckle noise reduction using Lee filter\n",
    "\n",
    "The Lee filter is a technique used to reduce speckle noise in SAR (Synthetic Aperture Radar) images. Speckle noise is the granular, random noise that occurs naturally in SAR observations and often affects image analysis.\n",
    "\n",
    "The following code implements a **Lee filter** commonly used to reduce speckle noise in synthetic aperture radar (SAR) images. This filter works by processing each pixel in the image using a sliding window (of the size defined by `window_size`). For each window, it computes the local mean and variance and determines a damping factor that controls how much smoothing is applied to the pixel.\n",
    "\n",
    "References:\n",
    "- [SAR Image Despeckling Using Refined Lee Filter](https://ieeexplore.ieee.org/document/7334965)\n",
    "- [Digital Image Enhancement and Noise Filtering by Use of Local Statistics](https://ieeexplore.ieee.org/document/4766994?rsource=https:%2F%2Flinks.esri.com%2FNoiseFilteringUsingLocalStats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf470817-76f6-489d-920d-0ef7e9267591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from skimage import img_as_float\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "# Define a lee filter function\n",
    "\n",
    "\n",
    "def lee_filter(image, size):\n",
    "    \"\"\"\n",
    "    Applies the Lee filter to an input image to reduce speckle noise.\n",
    "    \n",
    "    Parameters:\n",
    "        image (numpy.ndarray): The input image to be filtered.\n",
    "        size (int or tuple): The size of the local neighborhood (e.g., window size).\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: The filtered image.\n",
    "    \"\"\"\n",
    "    # Ensure the input image is a floating-point array for precision\n",
    "    image = image.astype(np.float32)\n",
    "    \n",
    "    # Calculate local mean and squared mean using uniform filter\n",
    "    local_mean = uniform_filter(image, size=size)\n",
    "    local_mean_sqr = uniform_filter(image**2, size=size)\n",
    "    \n",
    "    # Calculate local variance\n",
    "    local_variance = local_mean_sqr - local_mean**2\n",
    "    \n",
    "    # Estimate noise variance (overall variance of the image)\n",
    "    overall_variance = np.mean(local_variance)\n",
    "    \n",
    "    # Compute the filter weight\n",
    "    weight = local_variance / (local_variance + overall_variance)\n",
    "    weight = np.clip(weight, 0, 1)  # Ensure weight is in a valid range\n",
    "    \n",
    "    # Apply the Lee filter formula\n",
    "    filtered_image = local_mean + weight * (image - local_mean)\n",
    "    \n",
    "    return filtered_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2482700",
   "metadata": {},
   "source": [
    "#### Conversion from DN values to backscatter coefficients\n",
    "\n",
    "In time series analysis using multiple observation data, it is necessary to convert pixel values to backscatter coefficients. For details, see [Calibration and Validation](https://www.eorc.jaxa.jp/ALOS/jp/alos-2/a2_calval_j.htm)\n",
    "\n",
    "$$ \\sigma^0_{Q16} = 10 log_{10}<DN^2> + CF$$\n",
    "\n",
    "Note that <> represents averaging for noise reduction and -83.0 dB is used for CF. A coding example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef434ef6-9c86-46c6-ad7b-f6bd786c679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_image(image):\n",
    "    image = img_as_float(image)\n",
    "    calibrated_image = (10 * np.log10(image**2)) - 83\n",
    "    return calibrated_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc582be6",
   "metadata": {},
   "source": [
    "##### Performs preprocessing on each image data\n",
    "\n",
    "Processes the functions defined in the previous section on each image data and displays the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bb9b4-3d51-4704-aa08-a7ac2a538461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, re\n",
    "\n",
    "# File handling\n",
    "image_files = [f for f in os.listdir() if f.endswith('.tif')]\n",
    "preprocessed_images = []\n",
    "\n",
    "for file in image_files:\n",
    "    with rasterio.open(file) as src:\n",
    "        if src.count >= 1:\n",
    "            img = src.read(1)  # Read the first band\n",
    "        else:\n",
    "            raise ValueError(f\"File {file} does not contain a valid band.\")\n",
    "    \n",
    "    # Step 1: Apply speckle filter\n",
    "    filtered_img = lee_filter(img, size=5)\n",
    "    \n",
    "    # Step 2: Convert to backscatter coefficients\n",
    "    calibrated_img = calibrate_image(filtered_img)\n",
    "    preprocessed_images.append(calibrated_img)\n",
    "\n",
    "# Define number of rows and compute columns dynamically\n",
    "nrows = 3\n",
    "ncols = math.ceil(len(preprocessed_images) / nrows)\n",
    "\n",
    "# Create subplots grid\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "\n",
    "# Flatten axes to simplify indexing (even if nrows > 1)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each image\n",
    "for i, image in enumerate(preprocessed_images):\n",
    "    axes[i].imshow(image, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(re.search(r\"-(\\d{6})-\", image_files[i]).group(1))\n",
    "\n",
    "# Turn off unused axes if there are any\n",
    "for ax in axes[len(preprocessed_images):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e41ec0",
   "metadata": {},
   "source": [
    "The area with the smallest backscatter coefficient (dark area around the center) represents the water area. The water area appears from October 11 to November 3, which is [waterlogged due to heavy rainfall caused by Typhoon No. 19 in 2019](https://ja.wikipedia.org/wiki/%E5%85%AB%E3%83%83%E5%A0%B4%E3%83%80%E3%83%A0#%E4%BB%A4%E5%92%8C%E5%85%83%E5%B9%B4%E6%9D%B1%E6%97%A5%E6%9C%AC%E5%8F%B0%E9%A2%A8). The fact that the surface of the water was visible for several months afterward suggests that the water was released over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9329f",
   "metadata": {},
   "source": [
    "## 2.2. Analyze changes by color composite image\n",
    "\n",
    "Changes can be analyzed by color compositing SAR satellite data with different observation dates. Here is an example of assigning October 11, 2020 (pre-typhoon) to the red channel and November 3, 2019 (post-typhoon) to the green and blue channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f868072-6aae-4208-b589-8c628b7f9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "red   = preprocessed_images[image_files.index('IMG-HH-ALOS2290760720-191011-UBSR2.1GUA.tif')]\n",
    "green = preprocessed_images[image_files.index('IMG-HH-ALOS2294160720-191103-UBSR2.1GUA.tif')]\n",
    "blue  = preprocessed_images[image_files.index('IMG-HH-ALOS2294160720-191103-UBSR2.1GUA.tif')]\n",
    "\n",
    "# Stack bands into RGB image array\n",
    "rgb_image = np.stack([red, green, blue], axis=-1)\n",
    "\n",
    "# Normalize bands for better visibility (optional)\n",
    "rgb_image = (rgb_image - rgb_image.min()) / (rgb_image.max() - rgb_image.min())  # Normalize to [0, 1]\n",
    "\n",
    "# Show RGB composite\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(rgb_image)\n",
    "plt.title(\"Color Composite with 191011 and 191103\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f38c2f",
   "metadata": {},
   "source": [
    "Red areas indicate areas that were flooded by the heavy rain on October 12. Black areas indicate areas that were still under water on October 11."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c6a71",
   "metadata": {},
   "source": [
    "#### (Optional) Save the RGB composite image as GeoTiff\n",
    "If you want to display the composite image in a GIS or other application, save it as a GeoTIFF with the same spatial information (coordinate reference system, geotransform, etc.) as the input bands. The following code saves the RGB composite while preserving the CRS and transformations of one of the input bands (e.g., the red band)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085abf73-4e75-41b5-bf6a-d7c23c44a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_tif = 'IMG-HH-ALOS2290760720-191011-UBSR2.1GUA.tif'\n",
    "outfile = \"export.tif\"\n",
    "\n",
    "# To get metadata, open the red band again\n",
    "with rasterio.open(meta_tif) as src:\n",
    "    # Update metadata to support 3 bands (RGB) and float32 data type.\n",
    "    rgb_meta = src.meta.copy()\n",
    "    rgb_meta.update({\n",
    "        \"count\": 3,           # RGB 3-band\n",
    "        \"dtype\": \"float32\",   # Normalized image data type\n",
    "        \"driver\": \"GTiff\",    # Make sure the output format is GeoTIFF.\n",
    "        \"compress\": \"Deflate\" # Compression option recommended due to file size bloat\n",
    "    })\n",
    "\n",
    "    # Write RGB images as GeoTIFF\n",
    "    with rasterio.open(outfile, \"w\", **rgb_meta) as dst:\n",
    "        # Write each channel into a separate band\n",
    "        dst.write((rgb_image[:, :, 0] * 255).astype(\"uint8\"), 1)  # Red channel\n",
    "        dst.write((rgb_image[:, :, 1] * 255).astype(\"uint8\"), 2)  # Green Channel\n",
    "        dst.write((rgb_image[:, :, 2] * 255).astype(\"uint8\"), 3)  # Blue Channel\n",
    "\n",
    "print(f\"RGB composite image saved to {outfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4254cb",
   "metadata": {},
   "source": [
    "## 2.3. Detecting changes in the water area of a dam\n",
    "\n",
    "Significant changes can be detected by calculating the difference images between the two time periods. In this section, data analysis is performed using October 11 and November 3 as examples.\n",
    "- Typhoon No. 19 hit Japan on October 12, 2019, so images from October 11, 2019 will be used for the pre-typhoon images.\n",
    "- For the post-typhoon image, we will use the image from November 3, 2019. This is the first available image after the typhoon.\n",
    "\n",
    "First, the observed data are visualized in the image and compared by time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb23bc-1fdd-4f52-8e51-d979596f6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pre_typhoon   = preprocessed_images[image_files.index('IMG-HH-ALOS2290760720-191011-UBSR2.1GUA.tif')]\n",
    "post_typhoon  = preprocessed_images[image_files.index('IMG-HH-ALOS2294160720-191103-UBSR2.1GUA.tif')]\n",
    "\n",
    "# Set up the figure for visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot each image and store one of them for the color bar\n",
    "im = axes[0].imshow(pre_typhoon, cmap='gray')  # Assign to `im` for color bar reference\n",
    "axes[0].set_title(\"Pre-Typhoon (No Water): 11 Oct 2019\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(post_typhoon, cmap='gray')\n",
    "axes[1].set_title(\"Post-Typhoon (Almost Full Water Level): 3 Nov 2019\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Add a color bar below all images without overlapping\n",
    "cbar_ax = fig.add_axes([0.2, 0.01, 0.6, 0.02])  # Centered below all images\n",
    "fig.colorbar(im, cax=cbar_ax, orientation='horizontal').set_label('Backscaetter coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee1a55",
   "metadata": {},
   "source": [
    "- Pre-typhoon: on October 11, 2019, the dam was not fully opened (completed in October 2019 and officially opened on April 1, 2020). Therefore, only a small river in the dam area can be seen in the image.\n",
    "- Post-Typhoon: On November 3, 2019, the water level of the dam was very high, even though the dam was not officially opened. This was due to Typhoon Hagibis hitting Japan on October 12, 2019, which brought heavy rains and caused the water level of the Yamba Dam to rise sharply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15413513",
   "metadata": {},
   "source": [
    "### 2.3.1. Calculate the difference between the two time periods\n",
    "\n",
    "Calculate the difference image to detect changes from October 12 to November 3 in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063fe28-a5b4-43eb-b736-eaf35a66d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "diff_img_1012_1103 = post_typhoon - pre_typhoon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8983eb",
   "metadata": {},
   "source": [
    "Display the difference image. Areas flooded by the typhoon are highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e109e21-e962-42f2-8438-a532a00c2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize results with a legend\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "# Plot the pre-typhoon image.\n",
    "img0 = axes[0].imshow(pre_typhoon, cmap='gray')\n",
    "axes[0].set_title(\"Pre-Typhoon Image\")\n",
    "axes[0].axis(\"off\")\n",
    "cbar0 = fig.colorbar(img0, ax=axes[0], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "cbar0.set_label(\"Intensity\")\n",
    "\n",
    "# Plot the post-typhoon image.\n",
    "img1 = axes[1].imshow(post_typhoon, cmap='gray')\n",
    "axes[1].set_title(\"Post-Typhoon Image\")\n",
    "axes[1].axis(\"off\")\n",
    "cbar1 = fig.colorbar(img1, ax=axes[1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "cbar1.set_label(\"Intensity\")\n",
    "\n",
    "# Plot the difference image\n",
    "img2 = axes[2].imshow(diff_img_1012_1103, cmap='gray')\n",
    "axes[2].set_title(\"Difference (Post - Pre)\")\n",
    "axes[2].axis(\"off\")\n",
    "cbar2 = fig.colorbar(img2, ax=axes[2], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "cbar2.set_label(\"Difference Value\")\n",
    "\n",
    "# Adjust layout and display plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af988f",
   "metadata": {},
   "source": [
    "The histogram of the difference image shows that the distribution of pixel values is normally distributed. Therefore, it seems possible to consider both sides as significant changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db02d55e-daff-4041-918c-e0c662abf890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of differences\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(diff_img_1012_1103.ravel(), bins=100, color='blue', alpha=0.7)\n",
    "plt.title(\"Histogram of Difference between Pre and Post typhoon image\")\n",
    "plt.xlabel(\"Difference Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936d241",
   "metadata": {},
   "source": [
    "##### Save the Difference Image as a GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the difference image as a GeoTIFF\n",
    "with rasterio.open(\".../IMG-HH-ALOS2290760720-191011-UBSR2.1GUA.tif\") as src:  # Replace with the path to your input file\n",
    "    # Read metadata\n",
    "    meta = src.meta.copy()\n",
    "\n",
    "# Update metadata for the difference image\n",
    "meta.update(dtype=rasterio.float32)\n",
    "\n",
    "# Save the difference image\n",
    "output_file = \"difference_image.tif\"\n",
    "with rasterio.open(output_file, \"w\", **meta) as dst:\n",
    "    dst.write(diff_img_1012_1103.astype(rasterio.float32), 1)\n",
    "\n",
    "print(f\"Difference image saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475d521",
   "metadata": {},
   "source": [
    "### 2.3.2. Detecting Significant Changes in Difference Images\n",
    "\n",
    "This section presents a procedure for detecting areas of water body change by considering 2.5% ($\\mu \\pm 2\\sigma$) on each side of the pixel value distribution as a significant change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132de48b",
   "metadata": {},
   "source": [
    "##### Calculate threshold by mean and standard deviation\n",
    "\n",
    "Calculate the pixel value mean (`mean_diff`) and standard deviation (`std_diff`) of the difference images.\n",
    "\n",
    "In the following cells:\n",
    "- lower_bound and upper_bound with μ±2σ.\n",
    "- Pixels within `[lower_bound, upper_bound]` are considered “no change” and pixels outside this range [`< lower_bound` or `> upper_bound`] are considered “changed”.\n",
    "- This method follows the assumption of a normal distribution and assumes that most pixels within ±2σ represent no change.\n",
    "\n",
    "Note: `diff_img_1012_1103` (the output of the previous section) represents the pixel-by-pixel difference between pre-typhoon and post-typhoon images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce0928-8ef3-4c0f-b307-fae70589721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation\n",
    "mean_diff = np.mean(diff_img_1012_1103)\n",
    "std_diff = np.std(diff_img_1012_1103)\n",
    "\n",
    "# Define threshold with μ±2σ\n",
    "lower_bound = mean_diff - 2 * std_diff\n",
    "upper_bound = mean_diff + 2 * std_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b8fd4",
   "metadata": {},
   "source": [
    "##### Apply a threshold to classify changed and no change areas.\n",
    "\n",
    "Create a binary map (`changed_area`) where each pixel is labeled as either \"changed\" or \"no change\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fbf59-2679-48b7-89a1-adc2a06b128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a threshold of μ±2σ\n",
    "changed_area = ((diff_img_1012_1103 < lower_bound) | (diff_img_1012_1103 > upper_bound)).astype(np.uint8)  # 1 for changed, 0 for no-change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb1ab1",
   "metadata": {},
   "source": [
    "##### Visualizing Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bb956-3890-4f04-8b4f-fd5c90c7db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap  # Import ListedColormap\n",
    "\n",
    "# `changed_area` is binary change map data, where \"changed\" is 1 and \"no change\" is 0.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "# Plot the results using a gray color map.\n",
    "ax.imshow(changed_area, cmap=ListedColormap(['black', 'white']))\n",
    "ax.set_title(\"Change Map between Pre-typhoon and Post-typhoon (μ ± 2σ Threshold)\")\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Create a custom legend with “no change” and “change” colors.\n",
    "no_change_patch = mpatches.Patch(color=\"black\", label=\"No Change\")  # Black is no change\n",
    "changed_patch = mpatches.Patch(color=\"white\", label=\"Changed\")      # White is change\n",
    "plt.legend(handles=[no_change_patch, changed_patch], loc=\"lower right\", borderaxespad=1)\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13c00a",
   "metadata": {},
   "source": [
    "Changes in the water area due to waterlogging of the dam were detected as “changed”.\n",
    "\n",
    "Pixels that are considered “changed” are scattered not only in the dam but also in the surrounding area, but these are noise. Since the radar incidence angle (the difference between the slope angle of the terrain and the altitude angle of the satellite) affects the observed values of the synthetic aperture radar, pre-processing to compensate for this effect may be necessary. [ALOS-2/PALSAR-2 data product L2.2 performs slope gradient correction processing, but it is processed only for ScanSAR and is released free of charge](https://www.eorc.jaxa.jp/ALOS/en/dataset/palsar2_l22_e.htm), and standard products are not provided.\n",
    "\n",
    "It is also important to exclude noise as described above by defining the region of interest in advance. For example, the shape of the water surface in a completely waterlogged condition could be stored in advance as a polygon layer in the GIS, and the change detection analysis could be processed only inside that polygon. It may also be useful to treat neighboring pixels as clusters and consider clusters smaller than a certain size as noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132aebe",
   "metadata": {},
   "source": [
    "### 2.3.3. (Reference) Compare with Sentinel-2 optical satellite imagery.\n",
    "\n",
    "#### Sample location 1\n",
    "\n",
    "**Difference between Pre-Typhoon image (observation date: October 11, 2019) and Post-Typhoon image (observation date: November 03, 2019)** \n",
    "\n",
    "![Changed-area1](new-img_Diff_Pre-Post.PNG)\n",
    "\n",
    "| ALOS-2 image (filtered image) | Sentinel-2 image |\n",
    "|-------------------------------|------------------|\n",
    "| Before Typhoon (observation date: October 11, 2019) | Before Typhoon (observation date: October 10-11, 2019) |\n",
    "| ![ALOS-2_pre1](validate-pre1.png) | ![Sentinel-2_pre1](sentinel2-pre1.png) |\n",
    "| After Typhoon (observation date: November 3, 2019) | After Typhoon (observation date: October 28 - November 03, 2019) |\n",
    "| ![ALOS-2_post1](validate-post1.png) | ![Sentinel-2_post1](sentinel2-post1.png) |\n",
    "\n",
    "#### Sample location 2\n",
    "\n",
    "**Difference between Pre-Typhoon image (observation date: October 11, 2019) and Post-Typhoon image (observation date: November 03, 2019)**\n",
    "\n",
    "![Changed-area2](new-img_Diff_Pre-Post2.PNG)\n",
    "\n",
    "| ALOS-2 image (filtered image) | Sentinel-2 image |\n",
    "|-------------------------------|------------------|\n",
    "| Before Typhoon (observation date: October 11, 2019) | Before Typhoon (observation date: October 10-11, 2019) |\n",
    "| ![ALOS-2_pre2](validate-pre2.png) | ![Sentinel-2_pre2](sentinel2-pre2.png) |\n",
    "| After Typhoon (observation date: November 3, 2019) | After Typhoon (observation date: October 28 - November 03, 2019) |\n",
    "| ![ALOS-2_post2](validate-post2.png) | ![Sentinel-2_post2](sentinel2-post2.png) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c869f2",
   "metadata": {},
   "source": [
    "## 2.4 Advantages and uses of this exercise procedure\n",
    "\n",
    "### Remote monitoring and surveys\n",
    "\n",
    "- This is a hint for use in monitoring infrastructure in remote areas such as the Yamba Dam. In recent years, with the development of IoT and satellite communications, simply installing sensors may be sufficient. However, when installing sensors everywhere is costly, combining it with satellite data is effective.\n",
    "\n",
    "- In areas where infrastructure is being developed for the first time, there is no information necessary to plan the installation of sensors in the first place. In such cases, being able to analyze the dynamics **even roughly** using satellite data will contribute to reducing the investigation costs required for planning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
