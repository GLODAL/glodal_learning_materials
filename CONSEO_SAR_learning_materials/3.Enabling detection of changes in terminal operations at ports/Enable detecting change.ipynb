{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9966b782-802a-47de-a7ff-34e4c5d9ec27",
   "metadata": {},
   "source": [
    "# 3. Enable detecting changes of terminal operations in ports\n",
    "\n",
    "This section is designed for learners who are interested in detecting changes of terminal operations in ports with ALOS-2 - case study of Nagoya, Japan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a1905-410b-4893-93c6-6655c5f3acfe",
   "metadata": {},
   "source": [
    "## Here are the key learning objectives:\n",
    "- Preprocess to reduce speckle noises\n",
    "- Visual ALOS-2 satellite imagery for Toyota's facility in Nagoya port\n",
    "- Change detection of the port operation in the COVID-19 crisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956e048-6033-4e7e-83d5-cdb4660e5bb4",
   "metadata": {},
   "source": [
    "## 3.1 Preprocess to reduce speckle noises\n",
    "\n",
    "In this section, we focus on preparing ALOS-2 Synthetic Aperture Radar (SAR) imagery for analysis.\n",
    "- downloading ALOS-2 images\n",
    "- calibrated to adjust for sensor-related biases\n",
    "- apply a Lee filter to reduce speckle noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8376c-6ec3-4f51-bd63-09f297852947",
   "metadata": {},
   "source": [
    "**Download ALOS-2 imagery from Owncloud, and then unzip for the next step: data processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394578a2-7027-4b4c-8963-17d0fcc17c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/jovyan/shared/Sirinya/alos/ALOS2.1\n",
    "!wget --content-disposition \"https://owncloud.glodal-inc.net/owncloud/index.php/s/7LpA8rRJjIUFabL/download\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620fdb70-ba60-46a1-a21f-d264da24f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \"Shimpomachi_ngo.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a2779-570d-48b9-8baa-da401a267045",
   "metadata": {},
   "source": [
    "**Load the ALOS-2 images**\n",
    "\n",
    "This Python code is for loading and reading ALOS-2 SAR images by loading the paths of all .tif files from the specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d85cab-23fb-44c0-9d30-562a143e9322",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814caea8-89cf-4623-a73c-47f9276da44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the ALOS-2 data folder\n",
    "data_folder = '/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/data'\n",
    "\n",
    "# Find all GeoTIFF files in the folder\n",
    "alos_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder) if f.endswith('.tif')]\n",
    "if not alos_files:\n",
    "    raise FileNotFoundError(\"No GeoTIFF files found in the specified directory.\")\n",
    "    \n",
    "# Display list of files found\n",
    "print(\"ALOS-2 files to visualize:\")\n",
    "for file in alos_files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e959a0a-ef99-4253-966a-4b9f5c9f83ff",
   "metadata": {},
   "source": [
    "**Visualize Images**\n",
    "\n",
    "This cell will visualize each image found in the folder, without displaying metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af0ea2-bba9-438a-b98c-8400bfe24372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Choose a color map\n",
    "color_map = 'gray'  # Options: 'gray', 'viridis', 'plasma', 'inferno', 'jet', 'cividis', etc.\n",
    "\n",
    "# Define the number of columns for the grid\n",
    "n_cols = 2\n",
    "n_rows = (len(alos_files) + n_cols - 1) // n_cols  # Calculate required rows based on the number of files\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 6))\n",
    "axes = axes.flatten()  # Flatten to make it easy to iterate over\n",
    "\n",
    "# Loop over each file and visualize the image with the selected color map\n",
    "for idx, alos_path in enumerate(alos_files):\n",
    "    with rasterio.open(alos_path) as src:\n",
    "        alos_image = src.read(1)  # Read the first band (Assuming single-band data)\n",
    "\n",
    "    # Plot the image in the respective subplot\n",
    "    ax = axes[idx]\n",
    "    img = ax.imshow(alos_image, cmap=color_map)\n",
    "    ax.set_title(f\"{os.path.basename(alos_path)} ({color_map})\")\n",
    "    ax.set_xlabel(\"X coordinate\")\n",
    "    ax.set_ylabel(\"Y coordinate\")\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(idx + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af917ed-e909-4dc9-98f6-e1d2c5601603",
   "metadata": {},
   "source": [
    "**Calibrate Images**\n",
    "\n",
    "After obtaining the data, apply radiometric calibration factors to convert digital numbers (DN) to backscatter values (dB) using the below formular:\n",
    "\n",
    "- σ0 = 10*log10(DN2) - 83.0 dB [ALOS-2 Calibration Result of ALOS-2](https://www.eorc.jaxa.jp/ALOS/en/alos-2/a2_calval_e.htm)\n",
    "\n",
    "NOTE: Radiometric calibration is essential for translating ALOS-2 SAR data into meaningful backscatter values that reflect the Earth's surface accurately. This process corrects for sensor biases, making the data comparable across different sensors and acquisition times. Proper calibration enables detailed analyses, such as environmental monitoring, land use classification, and disaster management, by ensuring consistent, physically accurate measurements.\n",
    "\n",
    "NOTE: The formula above is the same with the formula: 20 * np.log10(ALOS-2 data) - 83.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75d9060-1ebf-47af-ba20-7a8dc3f1cc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "# Define a function to calibrate the image\n",
    "def calibrate_image(image):\n",
    "    # Clip negative values to avoid taking log of non-positive values\n",
    "    clipped_image = np.clip(image, a_min=1e-10, a_max=None)  # Prevent log(0)\n",
    "    # Apply calibration formula\n",
    "    calibrated_image = (20 * np.log10(clipped_image)) - 83\n",
    "    return calibrated_image\n",
    "\n",
    "# Apply calibration to original images and store in a dictionary\n",
    "calibrated_images = {}\n",
    "for alos_path in alos_files:\n",
    "    with rasterio.open(alos_path) as src:\n",
    "        alos_image = src.read(1)  # Read the first band (Assuming single-band data)\n",
    "\n",
    "    # Calibrate the original image\n",
    "    calibrated_images[alos_path] = calibrate_image(alos_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3dd346-4e2f-429b-8bc7-1d654fbbd07c",
   "metadata": {},
   "source": [
    "**Apply Lee Filter to Calibrated Images**\n",
    "\n",
    "The Lee filter works by computing the local statistics (mean and variance) over a moving window and uses this to reduce speckle noise while preserving the edges. This cell defines the lee_filter function and applies it to each ALOS-2 image in the directory. It stores the filtered images in a dictionary, filtered_images.\n",
    "\n",
    "Note: The size=3 parameter in the lee_filter() function refers to the size of the square window or kernel used to compute the local statistics (mean, variance) for each pixel. In this case, a 3x3 window is applied around each pil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6725dde-728c-4d27-bd95-064da936f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "# Define the Lee filter function\n",
    "def lee_filter(image, size):\n",
    "    mean = uniform_filter(image, size=size)\n",
    "    mean_sqr = uniform_filter(image**2, size=size)\n",
    "    variance_img = mean_sqr - mean**2\n",
    "    overall_variance = variance_img.mean()\n",
    "    weight = variance_img / (variance_img + overall_variance)\n",
    "    filtered_image = mean + weight * (image - mean)\n",
    "    return filtered_image\n",
    "\n",
    "# Apply Lee filter to the calibrated images\n",
    "filtered_images = {}\n",
    "for alos_path, calibrated_image in calibrated_images.items():\n",
    "    filtered_images[alos_path] = lee_filter(calibrated_image, size=3)  # Adjust size as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a500bba-2c45-4454-8a7d-bf3623a563f9",
   "metadata": {},
   "source": [
    "**Visualize Original, Calibrated, and Filtered Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a196926-01c7-451b-aa84-2eb861cf3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import rasterio\n",
    "\n",
    "# Visualize Original, Calibrated, and Filtered Images side-by-side\n",
    "for alos_path in alos_files:\n",
    "    # Retrieve the original, calibrated, and filtered images\n",
    "    with rasterio.open(alos_path) as src:\n",
    "        alos_image = src.read(1)\n",
    "    calibrated_image = calibrated_images[alos_path]\n",
    "    filtered_image = filtered_images[alos_path]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(alos_image, cmap='gray')\n",
    "    plt.title(f\"Original Image - {os.path.basename(alos_path)}\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Calibrated Image\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(calibrated_image, cmap='gray')\n",
    "    plt.title(f\"Calibrated Image - {os.path.basename(alos_path)}\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Filtered Image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(filtered_image, cmap='gray')\n",
    "    plt.title(f\"Filtered Image - {os.path.basename(alos_path)}\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20fb9ba-187d-4d65-b1ce-88f5f8b35fff",
   "metadata": {},
   "source": [
    "**(Optional) Export the filtered images as GeoTIFF files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b722e3-78a2-4c91-a92c-c571cb47230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# Define the output path to save filtered GeoTIFF images\n",
    "output_folder = '/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Export filtered images as GeoTIFF\n",
    "for alos_path, filtered_image in filtered_images.items():\n",
    "    output_filename = os.path.join(output_folder, os.path.basename(alos_path).replace('.tif', '_filtered.tif'))\n",
    "    \n",
    "    with rasterio.open(alos_path) as src:\n",
    "        # Get metadata from the original image\n",
    "        meta = src.meta.copy()\n",
    "        meta.update({\n",
    "            'height': filtered_image.shape[0],\n",
    "            'width': filtered_image.shape[1],\n",
    "            'dtype': 'float32',  # Change to 'float32' for filtered images\n",
    "        })\n",
    "    \n",
    "    # Write the filtered image to a new GeoTIFF file\n",
    "    with rasterio.open(output_filename, 'w', **meta) as dst:\n",
    "        dst.write(filtered_image.astype('float32'), 1)  # Write the first band\n",
    "\n",
    "    print(f\"Filtered image saved as: {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff4750-cd73-4005-8e3a-e2f0397f056b",
   "metadata": {},
   "source": [
    "## 3.2. Visual ALOS-2 satellite imagery for Toyota's facility in Nagoya port\n",
    "Brief introduction to this section\n",
    "\n",
    "- Visualize several observations around production suppression under COVID-19 crisis. Compare them with high-res image on Google Earth for sampled locations.\n",
    "- Visualize the changes with a color composite and explain teh relevance with the production suppression.\n",
    "- Show a time-series profile for a sampled location/region indicating the preduction suppression in TOYOTA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05d157-88c8-4928-8b76-78a30e67be7c",
   "metadata": {},
   "source": [
    "### 3.2.1 Visualize several observations around production suppression under COVID-19 crisis. Compare them with high-res image on Google Earth for sampled locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51818a5a-85de-4a5a-a821-6cc869a7e9ef",
   "metadata": {},
   "source": [
    "**Visualizing the filtered images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709aed3-52c9-4773-b592-0445115430a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the folder containing filtered images\n",
    "filtered_images_folder = '/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img'\n",
    "\n",
    "# Find all GeoTIFF files in the folder\n",
    "filtered_files = [os.path.join(filtered_images_folder, f) for f in os.listdir(filtered_images_folder) if f.endswith('.tif')]\n",
    "if not filtered_files:\n",
    "    raise FileNotFoundError(\"No GeoTIFF files found in the specified directory.\")\n",
    "\n",
    "# Display list of filtered files found\n",
    "print(\"Filtered ALOS-2 files to visualize:\")\n",
    "for file in filtered_files:\n",
    "    print(file)\n",
    "\n",
    "# Choose a color map\n",
    "color_map = 'gray'  # You can change the color map as needed\n",
    "\n",
    "# Determine number of rows needed for the subplots\n",
    "num_images = len(filtered_files)\n",
    "num_columns = 2\n",
    "num_rows = (num_images + num_columns - 1) // num_columns  # Ceiling division to get rows\n",
    "\n",
    "# Create a figure with subplots\n",
    "plt.figure(figsize=(15, num_rows * 5))  # Adjust figure size based on number of rows\n",
    "\n",
    "# Loop over each filtered file and add to the subplot\n",
    "for i, filtered_path in enumerate(filtered_files):\n",
    "    with rasterio.open(filtered_path) as src:\n",
    "        filtered_image = src.read(1)  # Read the first band (Assuming single-band data)\n",
    "\n",
    "    # Create a subplot for each image\n",
    "    plt.subplot(num_rows, num_columns, i + 1)\n",
    "    plt.imshow(filtered_image, cmap=color_map)\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"{os.path.basename(filtered_path)}\")\n",
    "    plt.xlabel(\"X coordinate\")\n",
    "    plt.ylabel(\"Y coordinate\")\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67299e5-02f4-49c9-94cf-1b37f21969a1",
   "metadata": {},
   "source": [
    "**Compare the observations with Sentinel-2 image for sampled locations**\n",
    "\n",
    "By comparing observations from these two sources on matching dates, you can analyze how features or land cover in the sampled locations changed over time, gaining a fuller picture by using both SAR and optical perspectives. This can highlight subtle changes not visible in just one data type.\n",
    "\n",
    "- ALOS-2 (SAR): These images provide insights into surface changes and structures, regardless of weather or lighting conditions. The three dates (191127, 210303, and 220302) allow you to track changes in infrastructure and surface roughness across pre-crisis, in-crisis, and post-crisis periods.\n",
    "- Sentinel-2 (Optical): These images capture reflectance in visible and near-infrared bands. Comparing the Sentinel-2 images (November 2019, March 2021, March 2022) provides insights into land cover changes and activities around interesting areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cbf222",
   "metadata": {},
   "source": [
    "|The observations (ALOS-2 image : 191127)| \n",
    "|-----------------------|\n",
    "|![ALOS-2_1](9fil191127.png)|\n",
    "\n",
    "|ALOS-2 image (filtered image)|Sentinel-2 image (Nov19)|\n",
    "|------------------------|---------------------|\n",
    "|A|\n",
    "|![ALOS-2_A](9fil_1.png)|![Sentinel-2_A](9fil_2.png)|\n",
    "|B|\n",
    "|![ALOS-2_B](9fil_3.png)|![Sentinel-2_B](9fil_4.png)|\n",
    "|C|\n",
    "|![ALOS-2_C](9fil_5.png) |![Sentinel-2_C](9fil_6.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a289ebbe",
   "metadata": {},
   "source": [
    "|The observations (ALOS-2 image : 210303)|\n",
    "|-------------------------------|\n",
    "|![ALOS-2_1](10fil210303.png)|\n",
    "\n",
    "| ALOS-2 image (filtered image) | Sentinel-2 image (Mar21) |\n",
    "|-------------------------------|------------------|\n",
    "| A |\n",
    "| ![ALOS-2_A](10fil_1.png) | ![Sentinel-2_A](10fil_2.png) |\n",
    "| B |\n",
    "| ![ALOS-2_B](10fil_3.png) | ![Sentinel-2_B](10fil_4.png) |\n",
    "| C |\n",
    "| ![ALOS-2_C](10fil_5.png) | ![Sentinel-2_C](10fil_6.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc947c5",
   "metadata": {},
   "source": [
    "|The observations (ALOS-2 image : 220302)|\n",
    "|-------------------------------|\n",
    "|![ALOS-2_1](11fil220302.png)|\n",
    "\n",
    "| ALOS-2 image (filtered image) | Sentinel-2 image (Mar22) |\n",
    "|-------------------------------|------------------|\n",
    "| A |\n",
    "| ![ALOS-2_A](11fil_1.png) | ![Sentinel-2_A](11fil_2.png) |\n",
    "| B |\n",
    "| ![ALOS-2_B](11fil_3.png) | ![Sentinel-2_B](11fil_4.png) |\n",
    "| C |\n",
    "| ![ALOS-2_C](11fil_5.png) | ![Sentinel-2_C](11fil_6.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8d6a9-2f22-4dc8-9640-e635483492e9",
   "metadata": {},
   "source": [
    "### 3.2.2 Visualize the changes with a color composite and explain the relevance with the production suppression.\n",
    "\n",
    "Creating a temporal RGB composite image is useful for visualizing differences between multiple SAR images. Since we are working with ALOS-2 images, a common approach is to assign different bands or time-stamped images to the RGB channels.\n",
    "\n",
    "You can create a RGB composite by combining the two filtered images into the red, green, and blue channels. Since we have two images, one option is to assign one image to the red channel, and the other to the green channel, and use their average or an empty array for the blue channel.\n",
    "\n",
    "**Steps to create a false-color composite**\n",
    "\n",
    "1. Use three images or two images and create a synthetic third channel (e.g., by averaging).\n",
    "2. Assign these to the red, green, and blue channels.\n",
    "3. Normalize the pixel values so they are in the range [0, 1] to be displayed as an RGB image.\n",
    "4. Display the false-color composite using mapotlib.\n",
    "\n",
    "Note: You can replace red_channel, green_channel, and blue_channel with any filtered image paths you prefer, depending on what data or analysis aspect you wish to highlight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e966a12-0b92-4271-8dea-608f35b5f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume filtered_files is a list of file paths\n",
    "filtered_files = [\n",
    "    \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-191127_filtered.tif\",\n",
    "    \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-200304_filtered.tif\",\n",
    "    \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-200610_filtered.tif\",\n",
    "    \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-210303_filtered.tif\",\n",
    "    \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-210609_filtered.tif\",\n",
    "    \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-211124_filtered.tif\",\n",
    "    \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-220302_filtered.tif\"\n",
    "]\n",
    "    \n",
    "# Extract dates from filenames\n",
    "def extract_date(filename):\n",
    "    # Regex pattern to capture dates (e.g., '191127')\n",
    "    match = re.search(r'\\d{6}', filename)\n",
    "    return match.group(0) if match else \"Unknown date\"\n",
    "\n",
    "# Print each file with its index and date\n",
    "for index, file in enumerate(filtered_files):\n",
    "    date = extract_date(file)\n",
    "    print(f\"Index {index}: {file} (Date: {date})\")\n",
    "\n",
    "# Specify the indices of the two images to use\n",
    "red_index = 0  # Image index for the red channel\n",
    "green_index = 1  # Image index for the green channel\n",
    "blue_index = 1  # Reuse the green channel image for the blue channel\n",
    "\n",
    "# Load the images for the specified channels\n",
    "with rasterio.open(filtered_files[red_index]) as src_red:\n",
    "    red_channel = src_red.read(1)\n",
    "with rasterio.open(filtered_files[green_index]) as src_green:\n",
    "    green_channel = src_green.read(1)\n",
    "with rasterio.open(filtered_files[blue_index]) as src_blue:\n",
    "    blue_channel = src_blue.read(1)\n",
    "\n",
    "# Normalize the channels to the range [0, 1] for RGB visualization\n",
    "def normalize(image):\n",
    "    return (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "# Apply normalization\n",
    "red_channel_norm = normalize(red_channel)\n",
    "green_channel_norm = normalize(green_channel)\n",
    "blue_channel_norm = normalize(blue_channel)\n",
    "\n",
    "# Stack the normalized channels to create an RGB composite image\n",
    "rgb_composite = np.stack((red_channel_norm, green_channel_norm, blue_channel_norm), axis=-1)\n",
    "\n",
    "# Get dates for the channels\n",
    "red_date = extract_date(filtered_files[red_index])\n",
    "green_date = extract_date(filtered_files[green_index])\n",
    "blue_date = extract_date(filtered_files[blue_index])\n",
    "\n",
    "# Visualize the RGB composite\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(rgb_composite)\n",
    "plt.title(f\"RGB Composite Image (Red: {red_date}, Green: {green_date}, Blue: {blue_date})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38b301-b4fe-47d1-87a0-e51df5276702",
   "metadata": {},
   "source": [
    "**Explanation for visualizing RGB composites using Python**\n",
    "\n",
    "The visual output produced by the RGB composites highlights temporal changes between two ALOS-2 SAR images captured on 191127 and 200304. In the composite, areas that remain unchanged between the two dates are displayed in grayscale, resulting from the combination of RGB. The red regions indicate areas where objects or structures were present only in 191127, suggesting that they were removed or altered by 200304. Conversely, blue regions represent areas where objects appeared only in the 200304 image, indicating new developments or changes that occurred during this time. This type of visualization effectively highlights changes in infrastructure, land use, or other features over time, using the filtered images for precise change detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20340ecf-9eba-4097-b2e5-26e400d96307",
   "metadata": {},
   "source": [
    "### 3.2.3 Show a time-series profile for a sampled location/region indicating the preduction suppression in TOYOTA.\n",
    "\n",
    "This code analyzes temporal changes in ALOS-2 backscatter data across specified areas of interest (AOIs) using a stacked time-series raster image. By masking each AOI’s geometry on the stacked raster data, it calculates the median backscatter value for each time layer. The time layers correspond to ALOS-2 images from various dates for visualization purposes. The results are then plotted, showing backscatter trends over time for each AOI, which allows for tracking changes in reflective surface properties, potentially indicating shifts in surface conditions within the AOIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44aca6-d0a0-43e2-9a1f-a138e1bfd6c5",
   "metadata": {},
   "source": [
    "**Composing time-series data of ALOS data to identify changes**\n",
    "\n",
    "Show a time-series profile for a sampled location/region indicating the preduction suppression in TOYOTA.\n",
    "\n",
    "Composing a time-series stack involves combining multiple ALOS-2 images from different dates into a single multi-layer image. This way, each layer represents data from a specific date, allowing you to analyze temporal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56477943-2d52-42ff-9d6d-d9e02fde2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to the directory containing filtered images\n",
    "filtered_images_path = '/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img'\n",
    "\n",
    "# Initialize a list to store filtered images in a consistent format\n",
    "filtered_stack = []\n",
    "\n",
    "# Collect all filtered images into a stack\n",
    "for filename in os.listdir(filtered_images_path):\n",
    "    if filename.endswith('.tif'):  # Adjust this if your images are in a different format\n",
    "        image_path = os.path.join(filtered_images_path, filename)\n",
    "        with rasterio.open(image_path) as src:\n",
    "            filtered_image = src.read(1)  # Read the first band (2D)\n",
    "            filtered_stack.append(filtered_image)\n",
    "\n",
    "# Convert the list to a 3D numpy array (height, width, time)\n",
    "time_series_stack = np.stack(filtered_stack, axis=-1)\n",
    "\n",
    "# Display basic information about the stack\n",
    "print(\"Time-Series Stack Shape (Height, Width, Time):\", time_series_stack.shape)\n",
    "print(\"Number of Layers (Time Dimension):\", time_series_stack.shape[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b493339a-55e6-4bf3-b994-44857145c202",
   "metadata": {},
   "source": [
    "**Export the Time-Series Stack as a GeoTIFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0608db-cd4e-40b8-8b76-4f9b63a52ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import os\n",
    "\n",
    "# Initialize a list to store the paths of ALOS files\n",
    "alos_files = []\n",
    "\n",
    "# Collect all filtered images into alos_files\n",
    "for filename in os.listdir(filtered_images_path):\n",
    "    if filename.endswith('.tif'):  # Adjust this if your images are in a different format\n",
    "        alos_files.append(os.path.join(filtered_images_path, filename))\n",
    "\n",
    "# Define the export path for the output GeoTIFF\n",
    "output_path = 'alos2_time_series_stack_ngo1.tif'\n",
    "\n",
    "# Open one of the source images to retrieve metadata\n",
    "with rasterio.open(alos_files[0]) as src:\n",
    "    # Copy metadata from an existing file and update the count\n",
    "    metadata = src.meta.copy()\n",
    "    metadata.update({\n",
    "        'count': time_series_stack.shape[-1],  # Set count to number of layers (time dimension)\n",
    "        'dtype': 'float32'                     # Set data type\n",
    "    })\n",
    "\n",
    "# Write the multi-layer time-series stack to a GeoTIFF file\n",
    "with rasterio.open(output_path, 'w', **metadata) as dst:\n",
    "    for i in range(time_series_stack.shape[-1]):\n",
    "        # Write each layer as a separate band\n",
    "        dst.write(time_series_stack[:, :, i].astype('float32'), i + 1)\n",
    "\n",
    "print(f\"Time-Series Stack successfully exported to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd45dd-7c43-422f-9d35-449d1a43a9a6",
   "metadata": {},
   "source": [
    "![Stacked layer](1stacked.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141b1d1-c5b0-437a-a908-fca5c3a8c54c",
   "metadata": {},
   "source": [
    "Stacking ALOS-2 images involves combining multiple SAR images taken over the same area but at different times into a single multi-layered file. Here’s the interpretation of the output of the stacked image in different colors representing the following:\n",
    "\n",
    "**Black and White color:** These indicates no change occurred throughout the time series for that pixel. \n",
    "\n",
    "In this case, black and white tones indicate areas where no significant change has occurred across the time span covered by the stacked imagery. These areas remain stable, suggesting consistent levels of activity or unchanged surface conditions.\n",
    "\n",
    "**Multiple colors:** These colors indicate the areas where the change occurred. Since the stacked layer contains multiple time layers, the values represent the time layer index when a significant change occurs.\n",
    "\n",
    "In contrast, areas represented by multiple colors highlight locations where changes have occurred. These changes are detected in the backscatter values, which may signify variations in surface properties, such as increased container volume, shifts in port operations, or alterations in industrial activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d556aa-986c-44a6-9bb8-38a0e46bfcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00e8d714-56a4-41e2-b443-69acb5f1cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rasterio.features  # Import features explicitly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d4d25-419e-424d-a191-872daa884f18",
   "metadata": {},
   "source": [
    "**Defines the paths and parameters needed for processing**\n",
    "- Specify the file path to the stacked ALOS-2 image and any AOI (Area of Interest) files (You can create your own AOI file or download it from [here](https://owncloud.glodal-inc.net/owncloud/index.php/s/xPdaXgH00OwQKFQ)).\n",
    "- Define the years corresponding to each band in the stacked image, and create simulated time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de18975b-1a30-44ea-a4c5-fd3150424aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_image_path = '/home/jovyan/shared/Sirinya/alos/ALOS2.1/alos2_time_series_stack_ngo1.tif'\n",
    "aoi_paths = [\n",
    "    '/home/jovyan/shared/Sirinya/alos/ALOS2.1/aoi_toyota.gpkg'\n",
    "]\n",
    "years = [191127, 200304, 200610, 210303, 210609, 211124, 220302]  # Dates of imagery collection\n",
    "time_points = np.arange(0, len(years) * 7, 7)  # Time intervals as multiples of 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cb484-5be8-4d59-bb20-cca41c65aec8",
   "metadata": {},
   "source": [
    "**Reads the stacked ALOS-2 image data**\n",
    "- Open the stacked ALOS-2 image and read all bands (layers) into a 3D numpy array, with each band\n",
    "- representing a different time point in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0730324e-7843-4daf-acbf-9f8a10882412",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(stacked_image_path) as src:\n",
    "    stacked_data = src.read()  # stacked_data has shape (bands, height, width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b0646-8f27-434f-8c57-3804236610d6",
   "metadata": {},
   "source": [
    "**Processes each AOI to calculate median backscatter values**\n",
    "- Loop through each AOI file. For each AOI, create a mask based on the AOI geometry to isolate the region of interest.\n",
    "- Calculate the median backscatter value within the AOI for each time point (band) in the stacked image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adbe4390-8c5f-4c8a-b19b-52012c771763",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_values_all = {}  # Dictionary to store median values for each AOI\n",
    "\n",
    "for aoi_path in aoi_paths:\n",
    "    # Load the AOI geometry using geopandas\n",
    "    aoi_gdf = gpd.read_file(aoi_path)\n",
    "    \n",
    "    # Initialize an empty mask for the entire AOI, combining all geometries\n",
    "    combined_mask = np.zeros(stacked_data.shape[1:], dtype=bool)\n",
    "    for geom in aoi_gdf.geometry:\n",
    "        # If geometry is valid, rasterize it to match the stacked image resolution\n",
    "        if geom.is_valid:\n",
    "            mask = rasterio.features.geometry_mask([geom], transform=src.transform,\n",
    "                                                   invert=True, out_shape=combined_mask.shape)\n",
    "            combined_mask = np.logical_or(combined_mask, mask)\n",
    "\n",
    "    # Compute the median backscatter values for each band (time point)\n",
    "    median_values = []\n",
    "    for band in range(stacked_data.shape[0]):\n",
    "        band_data = stacked_data[band]  # Extract data for the current band\n",
    "        # Calculate median value for masked region\n",
    "        median_value = np.median(band_data[combined_mask])\n",
    "        median_values.append(median_value)\n",
    "\n",
    "    # Store median values for current AOI\n",
    "    aoi_name = aoi_path.split('/')[-1].split('.')[0]  # Extract AOI name from path\n",
    "    median_values_all[aoi_name] = median_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a597256-1cef-420b-bc18-461656365529",
   "metadata": {},
   "source": [
    "**Plots the median values over time for each AOI**\n",
    "- Plot the computed median backscatter values for the AOI over time. The x-axis represents time intervals\n",
    "- and dates, while the y-axis represents the median backscatter value in dB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b47be3b-75b6-482f-a95f-a5c63c78fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aoi_name, median_values in median_values_all.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_points, median_values, marker='o', label='Median AOI Value')\n",
    "\n",
    "    plt.title(f'Median Value of Change Area Over Time for {aoi_name}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Median Backscatter Value')\n",
    "    plt.xticks(time_points, labels=years, rotation=45)  # Display original years as labels\n",
    "    plt.grid()\n",
    "    plt.legend(title='AOI')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5098de-d56a-4329-9e3d-144564202166",
   "metadata": {},
   "source": [
    "**Overall Trend:**\n",
    "The graph shows a generally declining trend in Toyota's production metrics, indicated by negative values across all dates, with some fluctuations throughout the period. This downward trend is likely tied to the impact of COVID-19 disruptions and semiconductor shortages, which significantly affected production capacity. Toyota's efforts to recover production have been visible, but the data points suggest continued challenges, especially within domestic operations.\n",
    "\n",
    "**Time-Series Observations:**\n",
    "- 191127 to 200304: The graph begins with a decline, possibly due to early pandemic-related disruptions and the initial waves of COVID-19.\n",
    "- 200304 to 200610: A further decrease indicates deepening production impacts, which align with escalating pandemic issues and possibly initial global chip shortages.\n",
    "- 200610 to 210303: Slight recovery with an increase, suggesting minor improvements as Toyota aimed to resume regular production, despite ongoing pandemic effects.\n",
    "- 210303 to 210609: A positive shift hints at production adjustments and recovery attempts during this period, even as COVID-19 disruptions continued intermittently.\n",
    "- 210609 to 211124: A decrease reflects renewed challenges, likely due to COVID-19 resurgences and supply chain constraints affecting Toyota’s output.\n",
    "- 211124 to 220302: The final point, suggests incremental recovery, potentially as supply issues begin to stabilize and Toyota's production strategy adapts to ongoing limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de8e76-cffa-41c7-8ca0-309ddec0c909",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "The data points illustrate Toyota’s struggle to stabilize production through COVID-19 and a global chip shortage. Early declines reflect the pandemic’s severe impact, while later dates show minor improvements as Toyota resumed operations amid an easing lockdown environment in China. Temporary suspensions at plants and reduced capacity due to workforce shortages contributed to the observed fluctuations. Despite a promising global demand recovery, Toyota's domestic production faced persistent challenges, underscored by recurring dips in the graph. The production outlook remains cautiously optimistic as Toyota adapts to lingering semiconductor shortages and fluctuating pandemic conditions, with gradual recovery potential in the coming quarters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad7289a-4210-4c6f-ad49-7627e08e733c",
   "metadata": {},
   "source": [
    "## 3.3. Change detection of the port operation in the COVID-19 crisis\n",
    "\n",
    "- Sample observations for pre-crisis, in-crisis, and post-crisis (if available).\n",
    "- Calculate differences between two observations:\n",
    "     - pre-crisis and in-crisis: resession of TOYOTA’s productions\n",
    "     - in-crisis and post-crisis: recovery of TOYOTA’s productions\n",
    "- Validate the changes for sampled locations on historical imagereis of Google Earth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b9ea3-39cd-4fd6-9126-4e94c3d96437",
   "metadata": {},
   "source": [
    "### 3.3.1 Sample observations for pre-crisis, in-crisis, and post-crisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78508a-3ed4-44b7-a991-51ed58ebfa56",
   "metadata": {},
   "source": [
    "The selected images were referred by the article below to represent key phases in Toyota's operations during the COVID-19 pandemic:\n",
    "\n",
    "- Pre-crisis (191127): This date, November 27, 2019, serves as a baseline image, capturing conditions before the pandemic's impacts took hold in Japan.\n",
    "- In-crisis (200610): The image from June 10, 2020, aligns with the height of disruptions, particularly in Japan’s manufacturing and automotive sectors, impacted by COVID-19-related production cuts, supply chain disruptions (like chip shortages), and health adaptations. This timing provides insight into the operational challenges Toyota faced during the crisis.\n",
    "- Post-crisis (211124): By November 24, 2021, Japan was transitioning towards recovery. Toyota and other manufacturers saw signs of recovery, though intermittent COVID-19 outbreaks and residual component shortages still created challenges. This image reflects Toyota's cautious but gradual movement towards full operational capacity.\n",
    "\n",
    "Note: \n",
    "- [Toyota suspends some Japan factory output over COVID outbreak](https://www.reuters.com/business/autos-transportation/toyota-suspends-some-japan-factory-output-over-covid-outbreak-2022-07-27/)\n",
    "- [Toyota misses April-June output target but says may be turning corner](https://www.reuters.com/business/autos-transportation/toyotas-april-june-global-vehicle-production-falls-98-short-initial-target-2022-07-28/)\n",
    "- [Toyota suspends some Japan factory production due to COVID outbreak](https://www.reuters.com/business/autos-transportation/toyota-suspends-some-japan-factory-production-due-covid-outbreak-2022-08-09/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35feb6e-0549-4be1-9edb-7052d73d277f",
   "metadata": {},
   "source": [
    "**Define File Paths for Images**\n",
    "\n",
    "Define the file paths to the pre_crisis, in_crisis, and post_crisis images, so the program knows where to load them. Replace these placeholders with the actual paths on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e382e6fa-9773-49bb-815a-8bbe51b13079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your ALOS-2 images\n",
    "pre_crisis_image_path = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-191127_filtered.tif\"\n",
    "in_crisis_image_path = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-200610_filtered.tif\"\n",
    "post_crisis_image_path = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-211124_filtered.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe10ff4-e2d0-4171-b21a-81de0a1b54bf",
   "metadata": {},
   "source": [
    "**Define a Function to Read and Normalize an Image**\n",
    "\n",
    "Purpose of `read_image` function: To open an image, read the data, and normalize it for better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efcf1fff-4569-46fb-9b84-b0af57aca2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read and normalize an image\n",
    "def read_image(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image_data = src.read(1)  # Read the first band\n",
    "        image_data = (image_data - image_data.min()) / (image_data.max() - image_data.min())  # Normalize to [0, 1]\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939b72f-261e-421a-adb9-d45a28d5fc4c",
   "metadata": {},
   "source": [
    "**Read and Normalize the Images**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa7d5100-6714-4fc6-9666-6f411d122480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and normalize the images\n",
    "pre_crisis = read_image(pre_crisis_image_path)\n",
    "in_crisis = read_image(in_crisis_image_path)\n",
    "post_crisis = read_image(post_crisis_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff768b01-09b6-497e-a657-108091103aad",
   "metadata": {},
   "source": [
    "**Visualization the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f174e-cd3c-4893-9f2e-6ca69420f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the figure for visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot each image with color bar\n",
    "im1 = axes[0].imshow(pre_crisis, cmap='gray')\n",
    "axes[0].set_title(\"Pre_crisis: 191127\")\n",
    "axes[0].axis(\"off\")\n",
    "fig.colorbar(im1, ax=axes[0], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "im2 = axes[1].imshow(in_crisis, cmap='gray')\n",
    "axes[1].set_title(\"In_crisis: 200610\")\n",
    "axes[1].axis(\"off\")\n",
    "fig.colorbar(im2, ax=axes[1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "im3 = axes[2].imshow(post_crisis, cmap='gray')\n",
    "axes[2].set_title(\"Post_crisis: 211124\")\n",
    "axes[2].axis(\"off\")\n",
    "fig.colorbar(im3, ax=axes[2], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b56411-3e9f-4573-b33d-8335a9c1806b",
   "metadata": {},
   "source": [
    "### 3.3.2 Calculate differences between two observations\n",
    "\n",
    "- In this section, we use images in 191127 and 200610 to calculate the differences between pre-crisis and in-crisis of COVID-19.\n",
    "- For the differences between in-crisis and post-crisis of COVID-19, we use images in 200610 and 211124."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb8766-ec5c-495b-b3f7-4e4e83dbb40b",
   "metadata": {},
   "source": [
    "#### A. pre-crisis and in-crisis: resession of TOYOTA’s production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86bbaf7a-f63b-4365-b844-c294c3fff030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your ALOS-2 images\n",
    "pre_crisis_image_path = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-191127_filtered.tif\"\n",
    "in_crisis_image_path = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-200610_filtered.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d3caee5-a402-4b3a-bb8a-63952f73e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the images and read the data\n",
    "with rasterio.open(pre_crisis_image_path) as src_pre:\n",
    "    pre_crisis_data = src_pre.read(1)  # Read the first band\n",
    "    pre_crisis_meta = src_pre.meta  # Store metadata for output\n",
    "    pre_crisis_crs = src_pre.crs  # Store CRS\n",
    "\n",
    "with rasterio.open(in_crisis_image_path) as src_in:\n",
    "    in_crisis_data = src_in.read(1)  # Read the first band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "521897d1-681f-42ac-94b8-fa548cca65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images\n",
    "pre_crisis = read_image(pre_crisis_image_path)\n",
    "in_crisis = read_image(in_crisis_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212f716e-a285-46c6-9478-d530d1d72f12",
   "metadata": {},
   "source": [
    "**Verify the Images Have the Same Shape**\n",
    "\n",
    "Ensures that the images have matching dimensions, which is required to perform a pixel-wise difference calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e36ab58-47d7-4cb3-b73b-509726a69bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both images have the same shape\n",
    "if pre_crisis_data.shape != in_crisis_data.shape:\n",
    "    raise ValueError(\"The two images must have the same dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0643e5-ecae-48aa-a1a0-4849339c4d6f",
   "metadata": {},
   "source": [
    "**Calculate the Difference between in and post-crisis**\n",
    "\n",
    "Subtracts each pixel in the pre_crisis image from the corresponding pixel in the in_crisis image, resulting in a \"difference\" image that highlights changes between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84cb25dc-7567-4bdf-8bb0-9019bff9bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference\n",
    "difference_caseA = in_crisis_data - pre_crisis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec76be5-68c0-4f65-975c-e972cfb9d57d",
   "metadata": {},
   "source": [
    "**Visualization the Difference Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5eaa4e-e5bd-4dd1-9875-7967b8eca79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the figure for visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot pre_crisis Image with color bar\n",
    "im1 = axes[0].imshow(pre_crisis_data, cmap='gray')\n",
    "axes[0].set_title(\"Pre_crisis Image : 191127\")\n",
    "axes[0].axis(\"off\")\n",
    "fig.colorbar(im1, ax=axes[0], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# Plot in_crisis Image with color bar\n",
    "im2 = axes[1].imshow(in_crisis_data, cmap='gray')\n",
    "axes[1].set_title(\"In_crisis Image : 200610\")\n",
    "axes[1].axis(\"off\")\n",
    "fig.colorbar(im2, ax=axes[1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# Plot Difference Image with color bar\n",
    "im3 = axes[2].imshow(difference_caseA, cmap='RdYlGn')\n",
    "axes[2].set_title(\"Difference (In - Pre)\")\n",
    "axes[2].axis(\"off\")\n",
    "fig.colorbar(im3, ax=axes[2], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c4c74-921e-4d9f-b47d-8b3d2fb79fa0",
   "metadata": {},
   "source": [
    "**Plot Histogram of Difference Image (Before Classification) with Mean and Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30662e-c1e6-4eb2-b0b4-154ccd2c6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming the following variables are defined:\n",
    "# pre_crisis_data, in_crisis_data\n",
    "\n",
    "# Case A: Difference between in_crisis_data and pre_crisis_data\n",
    "difference_caseA = in_crisis_data - pre_crisis_data\n",
    "\n",
    "# Calculate mean, median, and standard deviation for case 1\n",
    "mean_diff_caseA = np.mean(difference_caseA)\n",
    "median_diff_caseA = np.median(difference_caseA)\n",
    "std_diff_caseA = np.std(difference_caseA)\n",
    "\n",
    "# Plot histogram for Case A\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(difference_caseA.ravel(), bins=50, color='blue', alpha=0.7)\n",
    "plt.axvline(mean_diff_caseA, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_diff_caseA:.2f}')\n",
    "plt.axvline(median_diff_caseA, color='orange', linestyle='dotted', linewidth=1, label=f'Median: {median_diff_caseA:.2f}')\n",
    "plt.title(\"Histogram of Difference Image (In Crisis - Pre Crisis)\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219a12d-bda5-42c1-a80d-ba8f0da68596",
   "metadata": {},
   "source": [
    "**Define Classification Thresholds and Apply Classification**\n",
    "\n",
    "This code classifies each pixel in an image (difference_caseA) into one of three classes based on its difference from the mean pixel value. By categorizing pixels into classes, we can highlight regions with distinct changes. The classification helps identify areas with no change, positive change, and negative change by comparing each pixel to the mean plus or minus one standard deviation. This approach is useful in monitoring the changes over time.\n",
    "\n",
    "Each class represents a different level of change relative to the mean:\n",
    "\n",
    "- **No Change (Class 1)**: Pixels assigned a value of 1 have values within one standard deviation of the mean. These pixels represent areas where changes are minimal, indicating stability or no significant change.Pixels\n",
    "- **Positive Change (Class 2)**: Pixels with a value of 2 are more than one standard deviation above the mean. These pixels represent areas of positive change, suggesting an increase in signal intensity or some new activity in the area.\n",
    "- **Negative Change (Class 3)**: Pixels with a value of 3 fall more than one standard deviation below the mean, representing areas of negative change. This could indicate a reduction in activity, removal of objects, or other decreases in signal intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4fd2c09-553c-4bd3-938e-5325fdb9534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_image_caseA = np.zeros_like(difference_caseA)  # Initialize classification array\n",
    "\n",
    "# Class 1: No Change (within one standard deviation of the mean)\n",
    "classified_image_caseA[(difference_caseA > mean_diff_caseA - std_diff_caseA) & \n",
    "                       (difference_caseA <= mean_diff_caseA + std_diff_caseA)] = 1  \n",
    "\n",
    "# Class 2: Positive Change (greater than one standard deviation above the mean)\n",
    "classified_image_caseA[difference_caseA > mean_diff_caseA + std_diff_caseA] = 2  \n",
    "\n",
    "# Class 3: Negative Change (greater than one standard deviation below the mean)\n",
    "classified_image_caseA[difference_caseA < mean_diff_caseA - std_diff_caseA] = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8050c4-1827-4551-a083-c27699a4048c",
   "metadata": {},
   "source": [
    "**Visualize the Classified Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c7a28-5a11-4a12-b586-5d7254a0d129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the classified image\n",
    "plt.imshow(classified_image_caseA, cmap='Spectral')\n",
    "plt.colorbar(label=\"Change Classes\")\n",
    "plt.title(\"Classified Change Detection (A)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d3914-5360-4249-8e03-6e42ec5b61ee",
   "metadata": {},
   "source": [
    "**Plot Histogram of Classified Image with Mean and Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1df89-cdde-451b-b144-516f4488e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and median of the classified image (class labels) for Case A\n",
    "mean_classified_caseA = np.mean(classified_image_caseA)\n",
    "median_classified_caseA = np.median(classified_image_caseA)\n",
    "\n",
    "# Plot histogram of the classified image for Case A\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(classified_image_caseA.ravel(), bins=np.arange(1, 5) - 0.5, color='blue', alpha=0.7)\n",
    "plt.axvline(mean_classified_caseA, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_classified_caseA:.2f}')\n",
    "plt.axvline(median_classified_caseA, color='orange', linestyle='dotted', linewidth=1, label=f'Median: {median_classified_caseA:.2f}')\n",
    "plt.title(\"Histogram of Classified Image (Case A: 3 Classes)\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks([1, 2, 3], ['No Change', 'Positive Change', 'Negative Change'])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.75)  # Optional: Add grid lines for better readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6144865-9d19-456a-884c-50b2a2505fb9",
   "metadata": {},
   "source": [
    "**Save the difference image and classified image as GeoTIFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff6a57-0e67-4757-b2f7-3658319ea098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to save the images for Case A\n",
    "difference_output_path_caseA = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/pre_in_difference_image_testA.tif\"\n",
    "classified_output_path_caseA = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/classified_change_detection_pre_in_testA.tif\"\n",
    "\n",
    "# Update metadata for saving as GeoTIFF\n",
    "pre_crisis_meta.update({\"driver\": \"GTiff\", \"count\": 1, \"dtype\": \"float32\"})\n",
    "\n",
    "# Save the difference image for Case 1\n",
    "with rasterio.open(difference_output_path_caseA, \"w\", **pre_crisis_meta) as dst:\n",
    "    dst.write(difference_caseA, 1)  # Write the difference for Case A to the first band\n",
    "\n",
    "print(f\"Difference image for Case A saved to {difference_output_path_caseA}\")\n",
    "\n",
    "# Update metadata for the classified image (using integer data type for class labels)\n",
    "classified_meta_caseA = pre_crisis_meta.copy()\n",
    "classified_meta_caseA.update({\"dtype\": \"int32\"})\n",
    "\n",
    "# Save the classified image for Case A\n",
    "with rasterio.open(classified_output_path_caseA, \"w\", **classified_meta_caseA) as dst:\n",
    "    dst.write(classified_image_caseA, 1)  # Write the classified image for Case A to the first band\n",
    "\n",
    "print(f\"Classified Change Detection image for Case A saved to {classified_output_path_caseA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc8fb75-4bb3-48b0-ab4e-a03d0dd3c82f",
   "metadata": {},
   "source": [
    "#### B: in-crisis and post-crisis: recovery of TOYOTA’s productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee4abc61-34e3-4920-8622-b2e3e17deda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your ALOS-2 images\n",
    "in_crisis_image_path = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-200610_filtered.tif\"\n",
    "post_crisis_image_path = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/filtered_img/HH-211124_filtered.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f1a1dd4-a6a6-428d-91c8-d4e5f4e03110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the images and read the data\n",
    "with rasterio.open(in_crisis_image_path) as src_pre:\n",
    "    in_crisis_data = src_pre.read(1)  # Read the first band\n",
    "    in_crisis_meta = src_pre.meta  # Store metadata for output\n",
    "    in_crisis_crs = src_pre.crs  # Store CRS\n",
    "\n",
    "with rasterio.open(post_crisis_image_path) as src_post:\n",
    "    post_crisis_data = src_post.read(1)  # Read the first band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a68fb3c8-f282-40c3-9b8a-4ad94ea70274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images\n",
    "in_crisis = read_image(in_crisis_image_path)\n",
    "post_crisis = read_image(post_crisis_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c69cb8a8-b3f6-470c-92ba-1fd4e4c58662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both images have the same shape\n",
    "if in_crisis_data.shape != post_crisis_data.shape:\n",
    "    raise ValueError(\"The two images must have the same dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba7e16-8793-4e31-862d-e4bc04ae1af6",
   "metadata": {},
   "source": [
    "**Calculate the Difference**\n",
    "\n",
    "Subtracts each pixel in the in_crisis image from the corresponding pixel in the post_crisis image, resulting in a \"difference\" image that highlights changes between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fee15675-fab0-467b-a4c3-e29e78db45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference\n",
    "difference_caseB = post_crisis_data - in_crisis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c03812-4ff8-42f2-9288-1c685b579c4a",
   "metadata": {},
   "source": [
    "**Visualization the Difference Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1624de3-b01b-4242-b2e5-06bcf1df9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the figure for visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot in_crisis Image with color bar\n",
    "im1 = axes[0].imshow(in_crisis_data, cmap='gray')\n",
    "axes[0].set_title(\"In_crisis Image : 200610\")\n",
    "axes[0].axis(\"off\")\n",
    "fig.colorbar(im1, ax=axes[0], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# Plot post_crisis Image with color bar\n",
    "im2 = axes[1].imshow(post_crisis_data, cmap='gray')\n",
    "axes[1].set_title(\"Post_crisis Image : 211124\")\n",
    "axes[1].axis(\"off\")\n",
    "fig.colorbar(im2, ax=axes[1], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# Plot Difference Image with color bar\n",
    "im3 = axes[2].imshow(difference_caseB, cmap='RdYlGn')\n",
    "axes[2].set_title(\"Difference (Post - In)\")\n",
    "axes[2].axis(\"off\")\n",
    "fig.colorbar(im3, ax=axes[2], orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98971920-64fe-407e-81a2-dccdb6ce8b8b",
   "metadata": {},
   "source": [
    "**Plot Histogram of Difference Image (Before Classification) with Mean and Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217679b-f545-4356-97dc-ef92ff06ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the following variable is defined:\n",
    "# post_crisis_data\n",
    "\n",
    "# Case B: Difference between post_crisis_data and in_crisis_data\n",
    "difference_caseB = post_crisis_data - in_crisis_data\n",
    "\n",
    "# Calculate mean, median, and standard deviation for case B\n",
    "mean_diff_caseB = np.mean(difference_caseB)\n",
    "median_diff_caseB = np.median(difference_caseB)\n",
    "std_diff_caseB = np.std(difference_caseB)\n",
    "\n",
    "# Plot histogram for Case B\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(difference_caseB.ravel(), bins=50, color='green', alpha=0.7)\n",
    "plt.axvline(mean_diff_caseB, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_diff_caseB:.2f}')\n",
    "plt.axvline(median_diff_caseB, color='orange', linestyle='dotted', linewidth=1, label=f'Median: {median_diff_caseB:.2f}')\n",
    "plt.title(\"Histogram of Difference Image (Post Crisis - In Crisis)\")\n",
    "plt.xlabel(\"Pixel Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac379f-991f-4046-a348-619b5b644a4d",
   "metadata": {},
   "source": [
    "**Define Classification Thresholds and Apply Classification**\n",
    "\n",
    "This code classifies each pixel in an image (difference_caseA) into one of three classes based on its difference from the mean pixel value. By categorizing pixels into classes, we can highlight regions with distinct changes. The classification helps identify areas with no change, positive change, and negative change by comparing each pixel to the mean plus or minus one standard deviation. This approach is useful in monitoring the changes over time.\n",
    "\n",
    "Each class represents a different level of change relative to the mean:\n",
    "\n",
    "- **No Change (Class 1)**: Pixels assigned a value of 1 have values within one standard deviation of the mean. These pixels represent areas where changes are minimal, indicating stability or no significant change.Pixels\n",
    "- **Positive Change (Class 2)**: Pixels with a value of 2 are more than one standard deviation above the mean. These pixels represent areas of positive change, suggesting an increase in signal intensity or some new activity in the area.\n",
    "- **Negative Change (Class 3)**: Pixels with a value of 3 fall more than one standard deviation below the mean, representing areas of negative change. This could indicate a reduction in activity, removal of objects, or other decreases in signal intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfe35c24-de19-40c7-be17-6237c0149973",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_image_caseB = np.zeros_like(difference_caseB)  # Initialize classification array\n",
    "\n",
    "# Class 1: No Change (within one standard deviation of the mean)\n",
    "classified_image_caseB[(difference_caseB > mean_diff_caseB - std_diff_caseB) & \n",
    "                       (difference_caseB <= mean_diff_caseB + std_diff_caseB)] = 1  \n",
    "\n",
    "# Class 2: Positive Change (greater than one standard deviation above the mean)\n",
    "classified_image_caseB[difference_caseB > mean_diff_caseB + std_diff_caseB] = 2  \n",
    "\n",
    "# Class 3: Negative Change (greater than one standard deviation below the mean)\n",
    "classified_image_caseB[difference_caseB < mean_diff_caseB - std_diff_caseB] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd45423-8940-482f-87f5-211a284c9782",
   "metadata": {},
   "source": [
    "**Visualize the Classified Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563af6a-3ebe-462e-9953-3845f9364ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the classified image\n",
    "plt.imshow(classified_image_caseB, cmap='Spectral')\n",
    "plt.colorbar(label=\"Change Classes\")\n",
    "plt.title(\"Classified Change Detection (B)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151562e-fb38-4174-807a-8fe51616ad40",
   "metadata": {},
   "source": [
    "**Plot Histogram of Classified Image with Mean and Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef0d63-1727-4c02-a91d-3a8b9bc22152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and median of the classified image (class labels) for Case B\n",
    "mean_classified_caseB = np.mean(classified_image_caseB)\n",
    "median_classified_caseB = np.median(classified_image_caseB)\n",
    "\n",
    "# Plot histogram of the classified image for Case B\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(classified_image_caseB.ravel(), bins=np.arange(1, 5) - 0.5, color='green', alpha=0.7)\n",
    "plt.axvline(mean_classified_caseB, color='red', linestyle='dashed', linewidth=1, label=f'Mean: {mean_classified_caseB:.2f}')\n",
    "plt.axvline(median_classified_caseB, color='orange', linestyle='dotted', linewidth=1, label=f'Median: {median_classified_caseB:.2f}')\n",
    "plt.title(\"Histogram of Classified Image (Case B: 3 Classes)\")\n",
    "plt.xlabel(\"Class Label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks([1, 2, 3], ['No Change', 'Positive Change', 'Negative Change'])\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.75)  # Optional: Add grid lines for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce624c-3c2f-434f-bd81-17bb379b9e84",
   "metadata": {},
   "source": [
    "**Save the difference image and classified image as GeoTIFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2124197d-60e5-49c2-8347-f2279a89b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to save the images for Case B\n",
    "difference_output_path_caseB = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/in_post_difference_image_testB.tif\"\n",
    "classified_output_path_caseB = \"/home/jovyan/shared/Sirinya/alos/ALOS2.1/Shimpomachi_ngo/classified_change_detection_in_post_testB.tif\"\n",
    "\n",
    "# Update metadata for saving as GeoTIFF\n",
    "in_crisis_meta.update({\"driver\": \"GTiff\", \"count\": 1, \"dtype\": \"float32\"})\n",
    "\n",
    "# Save the difference image for Case B\n",
    "with rasterio.open(difference_output_path_caseB, \"w\", **in_crisis_meta) as dst:\n",
    "    dst.write(difference_caseB, 1)  # Write the difference for Case B to the first band\n",
    "\n",
    "print(f\"Difference image for Case B saved to {difference_output_path_caseB}\")\n",
    "\n",
    "# Update metadata for the classified image (using integer data type for class labels)\n",
    "classified_meta_caseB = in_crisis_meta.copy()\n",
    "classified_meta_caseB.update({\"dtype\": \"int32\"})\n",
    "\n",
    "# Save the classified image for Case 2\n",
    "with rasterio.open(classified_output_path_caseB, \"w\", **classified_meta_caseB) as dst:\n",
    "    dst.write(classified_image_caseB, 1)  # Write the classified image for Case B to the first band\n",
    "\n",
    "print(f\"Classified Change Detection image for Case B saved to {classified_output_path_caseB}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee53098-9614-4777-a215-76ef2c491b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "288967ab-730d-43bc-ade5-fbab2ba23b78",
   "metadata": {},
   "source": [
    "### 3.3.3 Validate the changes for sampled locations on historical imagereis of Google Earth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca74538e-53fc-427d-bfde-5b809d9ee30a",
   "metadata": {},
   "source": [
    "**How to validate the changes for sampled locations on historical imageries of Sentinel-2**\n",
    "\n",
    "- Using differences between pre-typhoon and post-typhoon image.\n",
    "- Using the filtered data to validate changed area by using pre-typhoon (October 3, 2019) and post-typhoon (November 3, 2019) image.\n",
    "- Check the historical imagereis in Google Earth. Ig the Google Earth has no image in the day/period that we want to check, we can download Landsat or Sentinel-2 to check the historical imagereis instead.\n",
    "- In this case, we downloaded the Sentinel-2 images from [Google Earth Engine](https://code.earthengine.google.com/3ce320461a9fa2c7402b8e5f2f793f7f).\n",
    "- Download [QGIS](http://test.qgis.org/html/en/site/forusers/download.html) software.\n",
    "- Open differences between pre-typhoon and post-typhoon image, filtered data in pre-typhoon and post-typhoon image, and Sentinel-2 data in pre-typhoon and post-typhoon image in QGIS to visual validate changed area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05028cf2-5cd8-428e-b52d-6cba49080f8c",
   "metadata": {},
   "source": [
    "**Pre-crisys and In-crisis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8279c53-ad91-4f77-9be5-aa1d6e7e4e80",
   "metadata": {},
   "source": [
    "**Sample location 1**\n",
    "\n",
    "|Difference between Pre-crisis (191127) and In-crisis (200610)|\n",
    "|-------------------------------|\n",
    "|![12Dif_pi1](12Dif_pi1.png)|\n",
    "\n",
    "|ALOS-2 (filtered): Pre-crisis (191127) | Sentinel-2: Pre-crisis (Nov19)|\n",
    "|-------------------------------|------------------|\n",
    "| ![12Dif_pi1_1](12Dif_pi1_1.png) | ![12Dif_pi1_2](12Dif_pi1_2.png) |\n",
    "\n",
    "|ALOS-2 (filtered): Pre-crisis (200610) | Sentinel-2: In-crisis (Jun20)|\n",
    "|-------------------------------|------------------|\n",
    "| ![12Dif_pi1_3](12Dif_pi1_3.png) | ![12Dif_pi1_4](12Dif_pi1_4.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388b43f-effa-43f5-a96d-2668392f145e",
   "metadata": {},
   "source": [
    "**Sample location 2**\n",
    "\n",
    "|Difference between Pre-crisis (191127) and In-crisis (200610)|\n",
    "|-------------------------------|\n",
    "|![12Dif_pi2](12Dif_pi2.png)|\n",
    "\n",
    "|ALOS-2 (filtered): Pre-crisis (191127) | Sentinel-2: Pre-crisis (Nov19)|\n",
    "|-------------------------------|------------------|\n",
    "| ![12Dif_pi2_1](12Dif_pi2_1.png) | ![12Dif_pi2_2](12Dif_pi2_2.png) |\n",
    "\n",
    "|ALOS-2 (filtered): Pre-crisis (200610) | Sentinel-2: In-crisis (Jun20)|\n",
    "|-------------------------------|------------------|\n",
    "| ![12Dif_pi2_3](12Dif_pi2_3.png) | ![12Dif_pi2_4](12Dif_pi2_4.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8f81a-2fe9-423e-aa42-8fc464411a5c",
   "metadata": {},
   "source": [
    "**In-crisis and Post-crisis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3609c-780e-4f9d-80c8-2e45c070e857",
   "metadata": {},
   "source": [
    "**Sample location 1**\n",
    "\n",
    "|Difference between In-crisis (200610) and Post-crisis (211124)|\n",
    "|-------------------------------|\n",
    "|![13Dif_ip1](13Dif_ip1.png)|\n",
    "\n",
    "|ALOS-2 (filtered): In-crisis (200610) | Sentinel-2: In-crisis (Jun20)|\n",
    "|-------------------------------|------------------|\n",
    "| ![13Dif_ip1_1](13Dif_ip1_1.png) | ![13Dif_ip1_2](13Dif_ip1_2.png) |\n",
    "\n",
    "|ALOS-2 (filtered): Post-crisis (211124) | Sentinel-2: Post-crisis (Nov21)|\n",
    "|-------------------------------|------------------|\n",
    "| ![13Dif_ip1_3](13Dif_ip1_3.png) | ![13Dif_ip1_4](13Dif_ip1_4.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361f90e-e371-48fd-912c-23b47d123ad1",
   "metadata": {},
   "source": [
    "**Sample location 2**\n",
    "\n",
    "|Difference between In-crisis (200610) and Post-crisis (211124)|\n",
    "|-------------------------------|\n",
    "|![13Dif_ip2](13Dif_ip2.png)|\n",
    "\n",
    "|ALOS-2 (filtered): In-crisis (200610) | Sentinel-2: In-crisis (Jun20)|\n",
    "|-------------------------------|------------------|\n",
    "| ![13Dif_ip2_1](13Dif_ip2_1.png) | ![13Dif_ip2_2](13Dif_ip2_2.png) |\n",
    "\n",
    "|ALOS-2 (filtered): Post-crisis (211124) | Sentinel-2: Post-crisis (Nov21)|\n",
    "|-------------------------------|------------------|\n",
    "| ![13Dif_ip2_3](13Dif_ip2_3.png) | ![13Dif_ip2_4](13Dif_ip2_4.png) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92985d94-7ba0-41ca-84a9-1ae30dbcfbec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
