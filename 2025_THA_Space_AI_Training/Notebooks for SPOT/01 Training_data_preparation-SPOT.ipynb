{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efda990-915a-4f44-87a2-656814964f66",
   "metadata": {},
   "source": [
    "# Fine tuning the Prithvi model for land use mapping in Thailand\n",
    "\n",
    "## Learning objectives\n",
    "By the end of this session, learners should be able to:\n",
    "1. Learn how to split land use data into relevant use cases and rasterize the land use data for further analysis.\n",
    "2. Acquire skills in preprocessing SPOT satellite imagery, including the creation of NDVI and NDWI indices, as well as adjusting data types for efficient processing.\n",
    "3. Learn how to stack multiple SPOT images to build a composite image for analysis.\n",
    "4. Gain practical experience in dividing large remote sensing images into smaller, manageable 224 x 224 patch images.\n",
    "5. Be able to visualize both SPOT image patches and land use patches to understand the data structure.\n",
    "6. Learn how to compute mean and standard deviation for each band in the SPOT images to prepare the dataset for further machine learning or deep learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52f93e-ea5b-45f9-86ad-0fd7ba41e8fe",
   "metadata": {},
   "source": [
    "## 0. Download the demonstration datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59a025-bde5-4e30-9d77-069fe6d85a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -O SPOT-Khon_Kaen.tar.gz https://owncloud.glodal-inc.net/owncloud/index.php/s/46v0V7o5abSdqyi/download\n",
    "!tar xaf SPOT-Khon_Kaen.tar.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da7fa2-bd42-4d25-9774-c84d088d1fee",
   "metadata": {},
   "source": [
    "## 1. Splitting land use data into use cases and rasterizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3242316-3005-4869-9e7c-ce4f80be8e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "def remove_directory_recursively(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"Directory '{path}' has been removed.\")\n",
    "    else:\n",
    "        print(f\"Directory '{path}' does not exist.\")\n",
    "\n",
    "place_name='Khon-kaen'\n",
    "output_folder= place_name\n",
    "remove_directory_recursively(output_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "spot_images_folder_path = \"SPOT/A/SPOT\" \n",
    "lu_shp_path = \"SPOT/A/GT/gt_LU2022A.shp\"\n",
    "landuse_path= output_folder + \"/gt_LU2022A.raster.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0783dae-b7f9-4cdc-ad93-4757a8ad5d63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bbox = (102.379, 16.58, 102.418, 16.599)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(lu_shp_path)\n",
    "print(\"No of rows:\",len(gdf))\n",
    "print(\"CRS:\",gdf.crs)\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d3d337-fd8e-46f6-81bc-d631555835e9",
   "metadata": {},
   "source": [
    "### Splitting into LU use cases:\n",
    "\n",
    "| Land Use | Raster Value | Color Code | Remarks |\n",
    "|----------|----|----|----------|\n",
    "| Urban | 1 | red |\n",
    "| Agricultural | 2 | yellow | non-Para rubber, non-Oil palm classes |\n",
    "| Forest | 3 | green |\n",
    "| Water | 4 | blue |\n",
    "| Oil Palm | 5 | purple |\n",
    "| Para Rubber | 6 | pink |\n",
    "| Others | 0 | black | all other classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075f141-65e8-456c-a78a-c8720fd3dee5",
   "metadata": {},
   "source": [
    "### Encoding the Land use classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f13354-655e-421f-b50d-fa7447d0988e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_lu_code = []\n",
    "final_lu_class = []\n",
    "\n",
    "for row in gdf.itertuples():\n",
    "    if row.LU_DES_EN == 'Para rubber':\n",
    "        final_lu_code.append(6)\n",
    "        final_lu_class.append(\"PRB\")\n",
    "\n",
    "    elif row.LU_DES_EN == 'Oil palm':\n",
    "        final_lu_code.append(5)\n",
    "        final_lu_class.append(\"OIL\")\n",
    "\n",
    "    elif row.LUL1_CODE == 'W':\n",
    "        final_lu_code.append(4)\n",
    "        final_lu_class.append(\"WTR\")\n",
    "\n",
    "    elif row.LUL1_CODE == 'F':\n",
    "        final_lu_code.append(3)\n",
    "        final_lu_class.append(\"FOR\")\n",
    "\n",
    "    elif row.LUL1_CODE == 'A':\n",
    "        final_lu_code.append(2)\n",
    "        final_lu_class.append(\"AGR\")\n",
    "\n",
    "    elif row.LUL1_CODE == 'U':\n",
    "        final_lu_code.append(1)\n",
    "        final_lu_class.append(\"URB\")\n",
    "\n",
    "    else:\n",
    "        final_lu_code.append(0)\n",
    "        final_lu_class.append(\"X\")\n",
    "\n",
    "gdf['final_lu_code'] = final_lu_code\n",
    "gdf['final_lu_class'] = final_lu_class\n",
    "\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab40af-cdc5-4de8-9e40-f5d0d426036b",
   "metadata": {},
   "source": [
    "### Rasterize land use (LU) data based on a given SPOT satellite image\n",
    "Note: Rasterization is the process of converting vector data (such as polygons representing land use classes) into a raster format (a grid of pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce362f5b-2172-4bc1-b921-ec2839679ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import rasterio as rio\n",
    "from rasterio.features import rasterize\n",
    "import glob\n",
    "\n",
    "# define reference raster path\n",
    "spot_imgs_path = glob.glob(spot_images_folder_path + '/*.tif')[0] # e.g. \"SPOT/A/SPOT/img_SPOT2020A.tif\"\n",
    "\n",
    "with rio.open(spot_imgs_path) as ref_raster:\n",
    "    # get the details of the reference raster\n",
    "    crs = ref_raster.crs\n",
    "    transform = ref_raster.transform\n",
    "    width = ref_raster.width\n",
    "    height = ref_raster.height\n",
    "    dtype = ref_raster.dtypes[0]\n",
    "\n",
    "# check if gdf and spot image have the same crs\n",
    "print(\"SPOT CRS:\",crs)\n",
    "print(\"LU CRS:\",gdf.crs)\n",
    "\n",
    "# if crs is not the same\n",
    "if gdf.crs != crs:\n",
    "    print(\"CRS mismatch, reprojecting\")\n",
    "    gdf = gdf.to_crs(crs)\n",
    "    print(\"Updated LU CRS:\",gdf.crs)\n",
    "\n",
    "with rio.open(landuse_path, 'w', driver='GTiff',\n",
    "                   count=1, dtype=dtype, crs=crs,\n",
    "                   width=width, height=height, transform=transform, compress='Deflate') as dst:\n",
    "\n",
    "    rasterized = rasterize(\n",
    "        ((geom, value) for geom, value in zip(gdf.geometry, gdf['final_lu_code'])),\n",
    "        out_shape=(height, width),\n",
    "        transform=transform,\n",
    "        fill=0,  # Fill value for empty pixels\n",
    "        dtype=dtype\n",
    "    )\n",
    "    \n",
    "    # Write the rasterized data to the output raster\n",
    "    dst.write(rasterized, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49908463-f58e-4110-aba4-2fc263cfdb8d",
   "metadata": {},
   "source": [
    "### Visualizing rasterized land use data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b61ccd9-bfbf-4ff1-bde5-60ffb50184c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "\n",
    "# Step 1: read the raster file\n",
    "\n",
    "with rio.open(landuse_path) as src:\n",
    "    window = from_bounds(*bbox, transform=src.transform)\n",
    "    raster_data = src.read(1, window=window) #read just the 1st band\n",
    "    crs = src.crs\n",
    "     \n",
    "print(\"Raster CRS:\",crs) #check the coordinate reference system of the raster file\n",
    "    \n",
    "# Step 2: define the colormap\n",
    "# Colors are assigned based on value / Landuse type\n",
    "value_to_color = {\n",
    "    0:'gray',\n",
    "    1:'red',\n",
    "    2:'yellow',\n",
    "    3:'green',\n",
    "    4:'blue',\n",
    "    5:'purple',\n",
    "    6:'pink'}\n",
    "\n",
    "# create a colormap with these values\n",
    "colors = [value_to_color.get(i,'black') for i in range(0,max(value_to_color.keys()) + 1)]\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Step 3: Display the raster with the colormap\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(raster_data,cmap=cmap,interpolation='none')\n",
    "\n",
    "# Step 4: Add legend\n",
    "# define the raster value and corresponding land use type\n",
    "lu_legend = {0:'Others',\n",
    "             1:'Urban',\n",
    "             2:'Agricultural',\n",
    "             3:'Forest',\n",
    "             4:'Water',\n",
    "             5:'Oil Palm',\n",
    "             6:'Para Rubber'}\n",
    "\n",
    "legend_elements = [Patch(facecolor=color, edgecolor='black', label=lu_legend[value])\n",
    "                   for value, color in value_to_color.items()]\n",
    "plt.legend(handles=legend_elements, title=\"Legend\", loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "# show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b7056-da13-4db6-b468-f80e78281506",
   "metadata": {},
   "source": [
    "## 2. Preprocessing SPOT image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ce08c-efe0-4b87-afe2-14276499662a",
   "metadata": {},
   "source": [
    "## Setting up the working directory and file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e94c5-885c-4755-8654-b2fe6eaa1bb2",
   "metadata": {},
   "source": [
    "### Calculate NDVI and NDWI indicies from SPOT image and stack multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab0faa-6313-4222-82a1-26ea0a8465a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "def calculate_indices(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        red = src.read(1).astype(float)\n",
    "        green = src.read(2).astype(float)\n",
    "        blue = src.read(3).astype(float)\n",
    "        nir = src.read(4).astype(float)\n",
    "        meta = src.meta\n",
    "    epsilon = 1e-10\n",
    "    ndvi = (nir - red) / (nir + red + epsilon)\n",
    "    ndwi = (green - nir) / (green + nir + epsilon)\n",
    "    \n",
    "    return ndvi, ndwi, meta\n",
    "\n",
    "def process_and_stack_images(folder_path, output_path):\n",
    "    # Get all multiband images\n",
    "    image_files = sorted(glob.glob(os.path.join(folder_path, \"*.tif\")))\n",
    "    \n",
    "    if len(image_files) != 3:\n",
    "        raise ValueError(f\"Expected 3 images, found {len(image_files)}\")\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images: {image_files}\")\n",
    "    all_bands = []\n",
    "    for image_path in image_files:\n",
    "        print(f\"Processing {image_path}...\")\n",
    "        with rasterio.open(image_path) as src:\n",
    "            window = from_bounds(*bbox, transform=src.transform)\n",
    "            bands = [src.read(i, window=window) for i in range(1, 5)]  \n",
    "            meta = src.meta\n",
    "        ndvi, ndwi, _ = calculate_indices(image_path)\n",
    "        all_bands.extend(bands + [ndvi, ndwi])\n",
    "    \n",
    "    meta.update({\n",
    "        'count': len(all_bands),  #18 bands total(6 bands Ã— 3 images)\n",
    "        'dtype': 'float32',\n",
    "        'height': bands[0].shape[0],\n",
    "        'width':  bands[0].shape[1],        \n",
    "        'transform': src.window_transform(window),\n",
    "        'compress': 'Deflate'\n",
    "    })\n",
    "    \n",
    "    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)\n",
    "    print(f\"Saving stacked image to {output_path}...\")\n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "        for idx, band in enumerate(all_bands, start=1):\n",
    "            dst.write(band.astype(np.float32), idx)\n",
    "    print(\"Done with calculating and stacking all bands!\")\n",
    "    \n",
    "## It may take upto 5 min to calculate indices and stack image\n",
    "stacked_spot_image =os.path.join(output_folder,\"stack.tif\" ) # give file name to stack image\n",
    "process_and_stack_images(spot_images_folder_path, stacked_spot_image )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd799fb-56a3-4d9e-a275-a4ce61436343",
   "metadata": {},
   "source": [
    "## 3. Splitting into 224 x 224 patch images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c1fd7-c0a6-4450-9eb6-6b29c75c5943",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e045339-9e56-4e39-a9e3-38841839a716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import Window\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b8737-b855-4e09-9b21-7b60f8297ff8",
   "metadata": {},
   "source": [
    "### Extract the bounding box (extent) from the reference raster file and Clip the source_path raster to match the reference extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ced05-9faf-4c45-a546-6fc527634aea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_to_reference_extent(source_path, reference_path, output_path):\n",
    "    print(f\"Clipping {os.path.basename(source_path)} to reference extent...\")\n",
    "    # Get reference image extent\n",
    "    with rio.open(reference_path) as ref:\n",
    "        ref_bounds = ref.bounds\n",
    "        ref_bbox = box(ref_bounds.left, ref_bounds.bottom, ref_bounds.right, ref_bounds.top)\n",
    "        ref_gdf = gpd.GeoDataFrame({'geometry': [ref_bbox]}, crs=ref.crs)\n",
    "    \n",
    "    # Clip source to reference extent\n",
    "    with rio.open(source_path) as src:\n",
    "        ref_gdf = ref_gdf.to_crs(src.crs)\n",
    "        out_image, out_transform = mask(src, ref_gdf.geometry, crop=True)\n",
    "        \n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "        \n",
    "        with rio.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "    print(\"Clipping completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f925a5-696f-4018-a56e-b289c549deb3",
   "metadata": {},
   "source": [
    "### Create training patches of size 224*224 for both spot image and landuse image\n",
    "\n",
    "**Calculate the number of patches available along the width (x) and height (y) of the raster in regular grids.**\n",
    "- Divide the raster dimensions by the patch size and round up to ensure full coverage.\n",
    "- Calculate the total number of patches (total_patches).\n",
    "\n",
    "Using 224x224 patches ensures that the satellite image patches can directly serve as input for models like the Prithvi model or other pre-trained architectures without additional resizing, preserving details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d16c30-acb0-48e5-aad7-afa1a4897171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_rm_patches(img_path, ann_path, img_output_dir, ann_output_dir, num_patches, patch_size=224, prefix=\"patch\"):\n",
    "    #NOTE: prefix can be region name as well, e.g. muang-udon\n",
    "    # step 1: read the raster file (NOTE, ideally start with the LU then just get the corresponding patches of the SPOT/HLS images)\n",
    "    os.makedirs(img_output_dir, exist_ok=True)\n",
    "    os.makedirs(ann_output_dir, exist_ok=True)\n",
    "    \n",
    "    img = rio.open(img_path)\n",
    "    ann = rio.open(ann_path)\n",
    "\n",
    "    img_bands = img.count\n",
    "    ann_bands = ann.count\n",
    "\n",
    "    img_profile = img.profile\n",
    "    ann_profile = ann.profile\n",
    "    \n",
    "    width, height = img.width, img.height\n",
    "\n",
    "    for i in range(num_patches):\n",
    "        # step 2: randomize the top-left corner of the patch\n",
    "        x = np.random.randint(0, width - patch_size)\n",
    "        y = np.random.randint(0, height - patch_size)\n",
    "        print(\"Patch Coordinates:\",(x,y))\n",
    "\n",
    "        # step 3: define a window for the patch\n",
    "        window = Window(x, y, patch_size, patch_size)\n",
    "        img_patch_data = img.read(window=window)\n",
    "        ann_patch_data = ann.read(window=window)\n",
    "\n",
    "        # step 4: save to output file\n",
    "        img_output_path = os.path.join(img_output_dir, '{}_tile-{:02d}-{:02d}.tif'.format(prefix,x,y))\n",
    "        ann_output_path = os.path.join(ann_output_dir, '{}_tile-{:02d}-{:02d}.tif'.format(prefix,x,y))\n",
    "        img_profile.update({\n",
    "            'width': patch_size,\n",
    "            'height': patch_size,\n",
    "            'transform': rasterio.windows.transform(window, img.transform)\n",
    "        })\n",
    "        ann_profile.update({\n",
    "            'width': patch_size,\n",
    "            'height': patch_size,\n",
    "            'transform': rasterio.windows.transform(window, ann.transform)\n",
    "        })\n",
    "\n",
    "        with rio.open(img_output_path, 'w', **img_profile) as dst:\n",
    "            dst.write(img_patch_data)\n",
    "        with rio.open(ann_output_path, 'w', **ann_profile) as dst:\n",
    "            dst.write(ann_patch_data)\n",
    "\n",
    "def create_patches(image_path, output_dir, patch_size=224):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with rio.open(image_path) as src:\n",
    "        # Calculate number of patches\n",
    "        num_patches_x = int(np.ceil(src.width / patch_size))\n",
    "        num_patches_y = int(np.ceil(src.height / patch_size))\n",
    "        total_patches = num_patches_y * num_patches_x\n",
    "        \n",
    "        print(f\"Creating {total_patches} patches for {os.path.basename(image_path)}...\")\n",
    "        \n",
    "        # Create progress bar\n",
    "        pbar = tqdm(total=total_patches, desc=\"Creating patches\")\n",
    "        \n",
    "        for y in range(num_patches_y):\n",
    "            for x in range(num_patches_x):\n",
    "                # Define window for current patch\n",
    "                window = Window(x * patch_size, y * patch_size, patch_size, patch_size)\n",
    "                transform = rio.windows.transform(window, src.transform)\n",
    "                patch = src.read(window=window)\n",
    "                profile = src.profile.copy()\n",
    "                profile.update({\n",
    "                    'height': patch.shape[1],\n",
    "                    'width': patch.shape[2],\n",
    "                    'transform': transform\n",
    "                })\n",
    "                \n",
    "                # Use same naming pattern for both landuse and spot patches\n",
    "                patch_name = f\"patch_{x:03d}_{y:03d}.tif\"\n",
    "                output_path = os.path.join(output_dir, patch_name)\n",
    "                \n",
    "                with rio.open(output_path, 'w', **profile) as dest:\n",
    "                    dest.write(patch)\n",
    "                \n",
    "                pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "    print(f\"Patch creation completed for {os.path.basename(image_path)}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66506d-833d-4095-a6b6-eeb97aee627f",
   "metadata": {},
   "source": [
    "### Process images\n",
    "\n",
    "- Create directories for storing land use and SPOT image patches.\n",
    "- Align the land use raster to the extent of the SPOT imagery using the clip_to_reference_extent function.\n",
    "- Create patches for both the clipped land use raster and SPOT imagery using the create_patches function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88e657-25b6-4be4-8287-b2a4df0403ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_images(landuse_path, spot_path, output_base_dir):\n",
    "    print(\"Starting image processing...\")\n",
    "    \n",
    "    # Create output directories\n",
    "    landuse_patches_dir = os.path.join(output_base_dir, 'landuse_patches')\n",
    "    spot_patches_dir = os.path.join(output_base_dir, 'spot_patches')\n",
    "    \n",
    "    # 1. First clip landuse to spot extent\n",
    "    clipped_landuse_path = os.path.join(output_base_dir, 'clipped_landuse.tif')\n",
    "    clip_to_reference_extent(landuse_path, spot_path, clipped_landuse_path)\n",
    "    \n",
    "    # 2. Create patches for both images\n",
    "    remove_directory_recursively(landuse_patches_dir)\n",
    "    remove_directory_recursively(spot_patches_dir)\n",
    "    #create_patches(clipped_landuse_path, landuse_patches_dir)\n",
    "    #create_patches(spot_path, spot_patches_dir)\n",
    "    create_rm_patches(spot_path, clipped_landuse_path, spot_patches_dir, landuse_patches_dir, 300)\n",
    "    print(\"Image processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6939ad8-f6eb-4c4a-a361-90a1f4947d0a",
   "metadata": {},
   "source": [
    "This script processes land use and SPOT imagery for the region specified by the place_name variable (khon-kaen in this case). It aligns the land use raster to the SPOT imagery's extent and resolution, and then divides both datasets into smaller patches for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab7b17-4ca2-4df8-af5a-6f98d9bb1ea4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "process_images(\n",
    "    landuse_path=landuse_path, # File path of the landuse image\n",
    "    spot_path=stacked_spot_image,\n",
    "    output_base_dir=output_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bddcc4-fd85-4d3d-9dff-7ea8f0638123",
   "metadata": {},
   "source": [
    "## Filter the patches created above as some of them might not be clipped to 224*224 size\n",
    "\n",
    "Ensure all images in a folder are of the required size (224x224 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045a4e3-cea6-4e4d-a3b0-36db63a4aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patch_images(image_folder):\n",
    "    desired_width, desired_height = 224, 224\n",
    "    deleted_files = []\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.tif')]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing Images\", unit=\"image\"):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                width, height = src.width, src.height\n",
    "                if (width, height) != (desired_width, desired_height):\n",
    "                    os.remove(image_path)\n",
    "                    deleted_files.append(image_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total images processed: {len(image_files)}\")\n",
    "    print(f\"Images deleted: {len(deleted_files)}\")\n",
    "    if deleted_files:\n",
    "        print(\"Deleted files:\")\n",
    "        for file in deleted_files:\n",
    "            print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f07de6-c6d9-4e51-ba7c-aa42ce0e0149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "landuse_patch_folder = os.path.join(output_folder,'landuse_patches')\n",
    "spot_patch_folder = os.path.join(output_folder,'spot_patches')\n",
    "filter_patch_images(spot_patch_folder)\n",
    "filter_patch_images(landuse_patch_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747ac7f-ab20-49a3-a68c-22069acc5fb0",
   "metadata": {},
   "source": [
    "### Split the patches into train, test, and validation set\n",
    "\n",
    "This process is essential for training machine learning models, where datasets are divided into different subsets for training, validating, and evaluating the model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab646b-05aa-463b-8bc9-4eaead47c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def create_train_val_test_splits(\n",
    "    image_dir, \n",
    "    mask_dir, \n",
    "    output_dir,\n",
    "    train_ratio=0.70,  # 70% of the data will be used for training.\n",
    "    val_ratio=0.10,    # 10% of the data will be used for validation.\n",
    "    test_ratio=0.20,   # 20% of the data will be used for testing.\n",
    "    random_seed=42\n",
    "):\n",
    "\n",
    "    # Set random seed\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        for subdir in ['images', 'masks']:\n",
    "            os.makedirs(os.path.join(output_dir, split, subdir), exist_ok=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.tif')]\n",
    "    \n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    total_size = len(image_files)\n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * val_ratio)\n",
    "\n",
    "    train_files = image_files[:train_size]\n",
    "    val_files = image_files[train_size:train_size + val_size]\n",
    "    test_files = image_files[train_size + val_size:]\n",
    "    \n",
    "    def copy_files(file_list, split_name):\n",
    "        print(f\"\\nCopying {split_name} files...\")\n",
    "        for filename in file_list:\n",
    "            src_image = os.path.join(image_dir, filename)\n",
    "            dst_image = os.path.join(output_dir, split_name, 'images', filename)\n",
    "            shutil.copy2(src_image, dst_image)\n",
    "            src_mask = os.path.join(mask_dir, filename)\n",
    "            dst_mask = os.path.join(output_dir, split_name, 'masks', filename)\n",
    "            shutil.copy2(src_mask, dst_mask)\n",
    "    \n",
    "    split_files = {\n",
    "        'train': train_files,\n",
    "        'val': val_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "    \n",
    "    for split_name, files in split_files.items():\n",
    "        copy_files(files, split_name)\n",
    "        print(f\"{split_name} split: {len(files)} images\")\n",
    "\n",
    "    return {\n",
    "        'train_size': len(train_files),\n",
    "        'val_size': len(val_files),\n",
    "        'test_size': len(test_files)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0206e28-a09d-4d2e-91a9-b866cdc0c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "final_training_data_folder = os.path.join(output_folder,'final_training_data')\n",
    "remove_directory_recursively(final_training_data_folder)\n",
    "os.makedirs(final_training_data_folder, exist_ok=True)\n",
    "\n",
    "stats = create_train_val_test_splits(\n",
    "    image_dir=spot_patch_folder,\n",
    "    mask_dir=landuse_patch_folder,\n",
    "    output_dir=final_training_data_folder,\n",
    "    train_ratio=0.70,\n",
    "    val_ratio=0.10,\n",
    "    test_ratio=0.20,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"\\nData split summary:\")\n",
    "print(f\"Total images: {sum(stats.values())}\")\n",
    "for split_name, size in stats.items():\n",
    "    print(f\"{split_name}: {size} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
