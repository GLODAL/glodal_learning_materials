{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63d0c78-ef4d-4e0b-9238-ca871515b669",
   "metadata": {},
   "source": [
    "# Part 01: Preprocessing HLS and Land Use Data for Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27859ee-86ab-42ad-bb9c-8f0982f19ab5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073dd0c2-a3cb-4ab7-901d-a4bce1aaf7e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This section of the training materials focus on preprocessing HLS images and the corresponding LandUse data to be used for FINETUNING, this step can be skipped if the focus is only on model inference (e.g. using the pretrained model with minimal modifications).\n",
    "\n",
    "Sample data is located in ./training_materials/data/01_preprocessing.\n",
    "\n",
    "Listed below are the specific preprocessing steps included in this notebook.\n",
    "\n",
    "1. Create Cloud Mask for HLS images\n",
    "2. Convert to WGS84\n",
    "3. Stack three 6-band HLS images into one 18-band image\n",
    "4. Crop HLS image using Land Use extents\n",
    "5. Split HLS image into 224x224 pixels\n",
    "6. Get matching LU image per 224x224 patch/tile\n",
    "\n",
    "IMPORTANT:\n",
    "1. The sample data used for this part is Muang-Udon, Thailand. For larger regions which spans multiple HLS images, regional mosaic should be created first before proceeding with the data preprocessing.\n",
    "2. Ensure that the LandUse data and the HLS images has the same CRS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b6193-4d08-4402-8317-54e1b5a50acb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing Sample LU data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f16ac9-3331-450d-8f46-479e28118e19",
   "metadata": {},
   "source": [
    "The Muang-Udon sample raster dataset has 6 land use classes with the corresponding raster values and color code shown below:\n",
    "\n",
    "| Land Use | Raster Value | Color Code |\n",
    "|----------|----|----|\n",
    "| Urban | 1 | red |\n",
    "| Agricultural | 2 | yellow |\n",
    "| Forest | 3 | green |\n",
    "| Water | 4 | blue |\n",
    "| Oil Palm | 5 | purple |\n",
    "| Para Rubber | 6 | pink |\n",
    "\n",
    "IMPORTANT: Gaps in the Land use are due to the removal of Mixed/Miscellaneous classes (example: Golf Course, Garbage Dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3f99b-015a-4bad-ac5a-1fddc2da1e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://rgw.glodal-inc.net/public/01_preprocessing_hls_lu_raster.tar.xz\n",
    "!tar xaf 01_preprocessing_hls_lu_raster.tar.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4ec2d-abc7-46a7-ae61-01b7beca315d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Visualizing sample Muang-Udon Land Use data\n",
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# os is for handling paths, files, and folders\n",
    "# rasterio is used for handling raster data in python\n",
    "# numpy is used to manipulate matrix-like datasets similar to a raster dataset\n",
    "# matplotlib is used to visualize the raster data / plot charts, etc.\n",
    "\n",
    "# Step 1: read the raster file\n",
    "#raster_path = '../data/01_preprocessing/muang_udon_lu_raster/LU_muang-udon.tif' #change the raster path based on where you stored the raster file\n",
    "raster_path = '01_preprocessing/lu_raster/LU_muang-udon.tif'\n",
    "\n",
    "with rio.open(raster_path) as src:\n",
    "    raster_data = src.read(1) #read just the 1st band\n",
    "    crs = src.crs\n",
    "     \n",
    "print(\"Raster CRS:\",crs) #check the coordinate reference system of the raster file\n",
    "    \n",
    "# Step 2: define the colormap\n",
    "# Colors are assigned based on value / Landuse type\n",
    "value_to_color = {\n",
    "    1:'red',\n",
    "    2:'yellow',\n",
    "    3:'green',\n",
    "    4:'blue',\n",
    "    5:'purple',\n",
    "    6:'pink'}\n",
    "\n",
    "# create a colormap with these values\n",
    "colors = [value_to_color.get(i,'black') for i in range(0,max(value_to_color.keys()) + 1)]\n",
    "cmap = ListedColormap(colors)\n",
    "\n",
    "# Step 3: Display the raster with the colormap\n",
    "plt.figure(figsize=(6,6))\n",
    "#plt.title(\"Khon Kaen Use Map\")\n",
    "plt.imshow(raster_data,cmap=cmap,interpolation='none')\n",
    "\n",
    "# Step 4: Add legend\n",
    "# define the raster value and corresponding land use type\n",
    "lu_legend = {1:'Urban',\n",
    "             2:'Agricultural',\n",
    "             3:'Forest',\n",
    "             4:'Water',\n",
    "             5:'Oil Palm',\n",
    "             6:'Para Rubber'}\n",
    "\n",
    "legend_elements = [Patch(facecolor=color, edgecolor='black', label=lu_legend[value])\n",
    "                   for value, color in value_to_color.items()]\n",
    "plt.legend(handles=legend_elements, title=\"Legend\", loc='upper right', bbox_to_anchor=(1.5, 1))\n",
    "\n",
    "# show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b9ee9-8128-463f-8f83-4a733fe3f639",
   "metadata": {},
   "source": [
    "## Preprocessing HLS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a11a06-be47-42ef-afe4-89c053db5b0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 0: Creating an 'output' folder to store all outputs from this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecf468-354e-4a61-83d5-1586483af2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# check if the folder exists --> if not, create the folder.\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "    print(\"'output' folder CREATED successfully.\")\n",
    "else:\n",
    "    print(\"'output' folder ALREADY EXISTS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc97f6c6-9871-424a-b880-9f999d4e09f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Creating a cloud-free 18-band image stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b2993-d20f-4ba1-86bd-fc549a274419",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Fmask Reference Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf16cc-5b3a-488f-ae1b-e24d18bd1345",
   "metadata": {
    "tags": []
   },
   "source": [
    "The full details on how to use the Fmask layer to mask clouds in HLS data is available in the [HLS User Guide V2](https://lpdaac.usgs.gov/documents/1698/HLS_User_Guide_V2.pdf) page 17.\n",
    "\n",
    "The Fmask integer values are converted to the bit representation, as shown in the table below:\n",
    "| Bit number | Mask name | Bit value | Mask description |\n",
    "|-----|--------|-----|--------|\n",
    "| 7-6 | aerosol level | 11 | High aerosol |\n",
    "| 7-6 | aerosol level | 10 | Moderate aerosol |\n",
    "| 7-6 | aerosol level | 01 | Low aerosol |\n",
    "| 7-6 | aerosol level | 00 | Climatology aerosol |\n",
    "| 5 | Water | 1 | Yes |\n",
    "| 5 | Water | 0 | No |\n",
    "| 4 | Snow/ice | 1 | Yes |\n",
    "| 4 | Snow/ice | 0 | No |\n",
    "| 3 | Cloud shadow | 1 | Yes |\n",
    "| 3 | Cloud shadow | 0 | No |\n",
    "| 2 | Adjacent to cloud/shadow | 1 | Yes |\n",
    "| 2 | Adjacent to cloud/shadow | 0 | No |\n",
    "| 1 | Cloud | 1 | Yes |\n",
    "| 1 | Cloud | 0 | No |\n",
    "| 0 | Cirrus Reserved, but not used | NA |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3d0fe-1172-4a16-b54f-b85c49d62af7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2 Visualizing cloud mask layer for sample Muang-Udon HLS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51fc4bb-8f94-46a6-a85c-a04cc518ad60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- THIS SECTION USES THE SAME MODULES/PACKAGES AS THE CELL ABOVE ---\n",
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the folders with the HLS files\n",
    "hls_path = '01_preprocessing/hls' #change the path to the HLS images\n",
    "\n",
    "# IMPORTANT: there are 3 sets of HLS images inside the folder, as the Prithvi model for multi-temporal crop classification requires 3 time-periods/observations\n",
    "hls_date_folders = [folder for folder in os.listdir(hls_path)\n",
    "                    if os.path.isdir(os.path.join(hls_path, folder))\n",
    "                    and folder != '.ipynb_checkpoints']\n",
    "# '.ipynb_checkpoints' has to be removed from the list of HLS images since it is being created automatically\n",
    "# print(hls_date_folders) --> uncomment to show what are the folder names in the list\n",
    "\n",
    "for hls_folder in hls_date_folders:\n",
    "    print(\"Folder/Date:\", hls_folder)\n",
    "    \n",
    "    fmask_fname = [fname for fname in os.listdir(os.path.join(hls_path,hls_folder)) if 'Fmask' in fname][0]\n",
    "    print(fmask_fname)\n",
    "    \n",
    "    fmask_path = os.path.join(os.path.join(hls_path,hls_folder),fmask_fname)\n",
    "    \n",
    "    with rio.open(fmask_path) as src:\n",
    "        fmask_data = src.read(1)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(fmask_data,cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923bda21-3d91-44a6-901a-7a05ac404019",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.3 Creating and Applying cloudmask from Fmask layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f08c8c-ba68-4ae3-92ae-a67f1c7cb9c3",
   "metadata": {},
   "source": [
    "The values in the 'cloud_val_list' are the corresponding integer values that should be removed from the Fmask layer.\n",
    "\n",
    "The table below shows the integer value, the corresponding binary value, and the description from the Fmask reference table\n",
    "\n",
    "| Integer value | Binary value | Description |\n",
    "|-----|----------|----------------|\n",
    "| 194 | 11000010 | High aerosol, Cloud |\n",
    "| 130 | 10000010 | Moderate aerosol, Cloud |\n",
    "| 66 | 01000010 | Low aerosol, Cloud |\n",
    "| 200 | 11001000 | High aerosol, Cloud shadow |\n",
    "| 136 | 10001000 | Moderate aerosol, Cloud shadow |\n",
    "| 72 | 01001000 | Low aerosol, Cloud shadow |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6f774-748b-4949-81a0-115a6b06ceb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ESTIMATED RUNTIME: 1 minute\n",
    "\n",
    "#NOTE: the functions in this cell output a raster file for every step of the process, this is done so there is a \"checkpoint\" for every step\n",
    "# and the outputs for each process can be reviewed\n",
    "\n",
    "# --- THESE MODULES ARE USED BY THE CELLS ABOVE, COMMENT OUT IF NOT NECESSSARY TO IMPORT AGAIN ---\n",
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# additional modules for this specific cell\n",
    "from rasterio.mask import mask\n",
    "\n",
    "# functions for cloud masking\n",
    "def create_cloud_mask(fmask_path,\n",
    "                      exp_path,\n",
    "                      cloud_val_list=[194,130,66,200,136,72] #refer to the table above for reference\n",
    "                     ):\n",
    "    \n",
    "    with rio.open(fmask_path) as src:\n",
    "        meta = src.meta.copy()\n",
    "        ds_fmask = src.read(1)\n",
    "        print(meta)\n",
    "        cloud_mask = np.where(np.isin(ds_fmask, cloud_val_list),0,1)\n",
    "\n",
    "    with rio.open(exp_path, 'w', **meta) as dest:\n",
    "        dest.write(cloud_mask,1)\n",
    "\n",
    "\n",
    "def apply_cloud_mask(img_path,\n",
    "                     fmask_path,\n",
    "                     exp_path):\n",
    "\n",
    "    # read image source\n",
    "    with rio.open(img_path) as img_src:\n",
    "        # read img as 3D array (bands, height, width)\n",
    "        img_data = img_src.read()\n",
    "        profile = img_src.profile\n",
    "    \n",
    "    # read cloud mask\n",
    "    with rio.open(fmask_path) as fmask_src:\n",
    "        # read mask as 2D array (height, width)\n",
    "        cloud_mask = fmask_src.read(1)\n",
    "    \n",
    "    # check if cloud mask has the same size as image\n",
    "    if (cloud_mask.shape != (img_data.shape[1], img_data.shape[2])):\n",
    "        raise ValueError(\"The cloud mask and the image dimensions do not match.\")\n",
    "    \n",
    "    # apply the cloud mask to each band\n",
    "    # mask is binary: 1 (clear) and 0 (clouds)\n",
    "    masked_data = img_data * cloud_mask\n",
    "    \n",
    "    # save the masked image to a new file\n",
    "    with rio.open(exp_path, 'w', **profile) as dst:\n",
    "        dst.write(masked_data)\n",
    "        \n",
    "        \n",
    "####### actual run of the cloudmasking functions ########\n",
    "\n",
    "# NOTE: the 'hls_path' and 'hls_date_folders' are also used in the previous cell, comment out if not necessary\n",
    "\n",
    "# step 1: read the folders with the HLS files\n",
    "hls_path = '01_preprocessing/hls' #change the path to the HLS images\n",
    "\n",
    "hls_date_folders = [folder for folder in os.listdir(hls_path)\n",
    "                    if os.path.isdir(os.path.join(hls_path, folder))\n",
    "                    and folder != '.ipynb_checkpoints']\n",
    "\n",
    "\n",
    "# step 2: create a new folder under 'output' to save the cloud mask outputs\n",
    "cmask_outpath = 'output/cloudmask'\n",
    "\n",
    "if not os.path.exists(cmask_outpath):\n",
    "    os.makedirs(cmask_outpath)\n",
    "    print(\"Folder CREATED successfully.\")\n",
    "else:\n",
    "    print(\"Folder ALREADY EXISTS.\")\n",
    "\n",
    "# step 3: iterate over the 3 time periods/observations\n",
    "for hls_folder in hls_date_folders:\n",
    "    print(\"\\nFolder/Date:\", hls_folder)\n",
    "      \n",
    "    # step 3.1: create the date folder inside the 'output/01_cloudmask' folder\n",
    "    if os.path.exists(os.path.join(cmask_outpath,hls_folder)):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(os.path.join(cmask_outpath,hls_folder))\n",
    "        \n",
    "    # step 3.2: read the fmask file\n",
    "    fmask_fname = [fname for fname in os.listdir(os.path.join(hls_path,hls_folder)) if 'Fmask' in fname][0]\n",
    "    print(fmask_fname)\n",
    "    \n",
    "    # step 3.3: define the fmask and cmask (cloud mask) paths\n",
    "    fmask_path = os.path.join(os.path.join(hls_path,hls_folder),fmask_fname)\n",
    "    cmask_path = os.path.join(os.path.join(cmask_outpath,hls_folder),fmask_fname.replace('Fmask','Cmask'))\n",
    "    \n",
    "    # step 3.4: create cloudmask file\n",
    "    create_cloud_mask(fmask_path,cmask_path)\n",
    "    \n",
    "    # show the cloudmask\n",
    "    with rio.open(cmask_path) as src:\n",
    "        fmask_data = src.read(1)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(fmask_data,cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "    # step 3.5: apply cloud mask\n",
    "    for fname in os.listdir(os.path.join(hls_path,hls_folder)):\n",
    "        if fname == '.ipynb_checkpoints' or 'Fmask' in fname:\n",
    "            continue\n",
    "        \n",
    "        print(\"Applying Cloud Mask to {}\".format(fname))\n",
    "        apply_cloud_mask(os.path.join(os.path.join(hls_path,hls_folder),fname),\n",
    "                         cmask_path,\n",
    "                         os.path.join(os.path.join(cmask_outpath,hls_folder),fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a20eb9-7124-423e-afc4-9a6dc24c8ca9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.4 Stacking into 18-band HLS images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f59655-0a77-4209-80e5-518b5fe605f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ESTIMATED RUNTIME: <1 minute\n",
    "\n",
    "#NOTE: the functions in this cell output a raster file for every step of the process, this is done so there is a \"checkpoint\" for every step\n",
    "# and the outputs for each process can be reviewed\n",
    "\n",
    "# --- THESE MODULES ARE USED BY THE CELLS ABOVE, COMMENT OUT IF NOT NECESSSARY TO IMPORT AGAIN ---\n",
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# look for the 6 bands to combine (B | G | R | NIR | SWIR1 | SWIR 2)\n",
    "def search_bands(img_fname_list, ref_list = ['B02','B03','B04','B8A','B11','B12']):\n",
    "    fin_list = [fname for fname in img_fname_list if fname.split(\".\")[-2] in ref_list]\n",
    "    return fin_list\n",
    "\n",
    "# ensure that the bands are in order\n",
    "def order_bands(img_list,bands=['B02','B03','B04','B8A','B11','B12']):\n",
    "    new_list = img_list[:]\n",
    "    \n",
    "    for band in img_list:\n",
    "        new_id = bands.index(band.split(\".\")[-2])\n",
    "        #print(new_id)\n",
    "        new_list[new_id] = band\n",
    "\n",
    "    return new_list\n",
    "\n",
    "# stack images\n",
    "def stack_images(img_fpath_list,outpath):\n",
    "    # read metadata of first file\n",
    "    with rio.open(img_fpath_list[0]) as src0:\n",
    "        meta = src0.meta\n",
    "    \n",
    "    # update meta to reflect the number of layers\n",
    "    meta.update(count = len(img_fpath_list))\n",
    "\n",
    "    # read each layer and write it to stack\n",
    "    with rio.open(outpath, 'w', **meta) as dst:\n",
    "        for id, layer in enumerate(img_fpath_list, start=1):\n",
    "            with rio.open(layer) as src1:\n",
    "                dst.write_band(id, src1.read(1))\n",
    "\n",
    "# step 1: read the folders with the cloud-masked HLS files\n",
    "cm_hls_path = 'output/cloudmask' #change the path according to where you stored the cloudmasked data\n",
    "cm_hls_date_folders = [folder for folder in os.listdir(cm_hls_path)\n",
    "                    if os.path.isdir(os.path.join(cm_hls_path, folder))\n",
    "                    and folder != '.ipynb_checkpoints']\n",
    "\n",
    "# step 2: stack the images\n",
    "all_img_stack_list = [] #save all images to be stacked\n",
    "\n",
    "for cm_hls_folder in cm_hls_date_folders:\n",
    "    \n",
    "    img_list = [fname for fname in os.listdir(os.path.join(cm_hls_path,cm_hls_folder))\n",
    "                if fname.split(\".\")[-1] == 'tif'] #filtering for tif images only\n",
    "    \n",
    "    # step 2.1: search for the 6 bands to stack\n",
    "    fin_img_list = search_bands(img_list)\n",
    "    fin_img_list = order_bands(fin_img_list)\n",
    "    #print(fin_img_list)\n",
    "    \n",
    "    # step 2.2: get the paths of the images\n",
    "    fin_img_fpath_list = [os.path.join(os.path.join(cm_hls_path,cm_hls_folder),fname) for fname in fin_img_list]\n",
    "    print(fin_img_fpath_list)\n",
    "    all_img_stack_list = all_img_stack_list + fin_img_fpath_list\n",
    "    \n",
    "# step 3: stack all images \n",
    "out_stack_path = os.path.join('output','HLS_18bands.tif')\n",
    "stack_images(all_img_stack_list,out_stack_path)\n",
    "    \n",
    "# step 4: checking if the new stack images have 18bands and visualizing the raster\n",
    "with rio.open(out_stack_path) as src:\n",
    "    data = src.read()\n",
    "    print(\"\\nImage shape:\",data.shape)\n",
    "\n",
    "    # visualize the HLS file\n",
    "    rgb = src.read([4,3,2]) # change to [3,2,1] for RGB. [4,3,2] shows False Color\n",
    "    \n",
    "    # scale to 0-255 for visualization\n",
    "    scaled_rgb = np.zeros_like(rgb, dtype=np.uint8)\n",
    "\n",
    "    for i in range(3):\n",
    "        band = rgb[i]\n",
    "        min_val = np.min(band[band != 0])\n",
    "        max_val = np.max(band[band != 0])\n",
    "        scaled_rgb[i] =  ((band - min_val) / (max_val - min_val)*255).astype(np.uint8)\n",
    "    \n",
    "    scaled_rgb_new = scaled_rgb.transpose((1,2,0))\n",
    "\n",
    "    # display the RGB image\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(\"Muang Udon HLS Stack\")\n",
    "    plt.imshow(scaled_rgb_new)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b7623-c09b-4603-ae52-45ed62272d96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Crop HLS by LU bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf81b56d-1aa7-442d-8719-66ad96ad9615",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1 Convert LU raster to the same crs as the HLS image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4d3aa-6b70-4175-8228-92f574acf710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ESTIMATED RUNTIME: <1 minute\n",
    "\n",
    "#NOTE: the functions in this cell output a raster file for every step of the process, this is done so there is a \"checkpoint\" for every step\n",
    "# and the outputs for each process can be reviewed\n",
    "\n",
    "import os\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "\n",
    "# -- COMMENT OUT THIS SECTION IF YOU WISH TO USE GDAL FOR REPROJECTION --\n",
    "# from osgeo import gdal\n",
    "\n",
    "# def reproject_raster(input_path, output_path, target_crs='EPSG:4326'): \n",
    "#     '''target_crs = 4326 by default'''\n",
    "#     src_ds = gdal.Open(input_path)\n",
    "#     if not src_ds:\n",
    "#         raise FileNotFoundError(f\"Unable to open {input_path}\")\n",
    "\n",
    "#     # define the target CRS using EPSG code (e.g. 4326 for WGS 84)\n",
    "#     target_crs_wkt = target_crs\n",
    "\n",
    "#     # perform the reprojection using gdal.Warp\n",
    "#     warp_options = gdal.WarpOptions(dstSRS=target_crs_wkt)\n",
    "#     dst_ds = gdal.Warp(output_path, src_ds, options=warp_options)\n",
    "\n",
    "#     # flush and close datasets\n",
    "#     dst_ds.FlushCache()\n",
    "#     src_ds = None\n",
    "#     dst_ds = None\n",
    "# ------------------------------------------------------------------------\n",
    "      \n",
    "#hls_stack_path = 'output/muang-udon_HLS_18bands.tif' #change if the directory where the 18-band HLS stack is changed also\n",
    "#lu_raster_path = '../data/01_preprocessing/muang_udon_lu_raster/LU_muang-udon.tif'\n",
    "#lu_warped_path = 'output/muang-udon_LU_warped.tif'\n",
    "\n",
    "hls_stack_path = 'output/HLS_18bands.tif'\n",
    "lu_raster_path = '01_preprocessing/lu_raster/LU_muang-udon.tif'\n",
    "lu_warped_path = 'output//LU_muang-udon-warped.tif'\n",
    "\n",
    "# step 1: get the crs of the Stacked HLS image\n",
    "with rio.open(hls_stack_path) as hls_src:\n",
    "    hls_crs = hls_src.crs\n",
    "    hls_transform = hls_src.transform\n",
    "    # hls_width = hls_src.width\n",
    "    # hls_height = hls_src.height\n",
    "    hls_res = hls_src.res\n",
    "    print(\"HLS CRS:\",hls_crs)\n",
    "    print(\"HLS Resolution:\",hls_res)\n",
    "    \n",
    "# step 2: convert the LU raster into the same crs\n",
    "with rio.open(lu_raster_path) as lu_src:\n",
    "    print(\"Orig LU CRS:\",lu_src.crs)\n",
    "    transform , width, height = calculate_default_transform(\n",
    "        lu_src.crs,\n",
    "        hls_crs, #change CRS to HLS CRS\n",
    "        lu_src.width,\n",
    "        lu_src.height,\n",
    "        *lu_src.bounds,\n",
    "        resolution = hls_res) #change resolution to HLS res\n",
    "    \n",
    "    # update the meta for the reprojected raster\n",
    "    lu_meta = lu_src.meta.copy()\n",
    "    lu_meta.update({\n",
    "        'crs':hls_crs,\n",
    "        'transform':transform,\n",
    "        'width':width,\n",
    "        'height':height})\n",
    "\n",
    "    with rio.open(lu_warped_path, 'w', **lu_meta) as luw_src:\n",
    "        reproject(\n",
    "            source=lu_src.read(1), # read the first band\n",
    "            destination=rio.band(luw_src, 1), # write to the first band of the destination\n",
    "            src_transform=lu_src.transform,\n",
    "            src_crs=lu_src.crs,\n",
    "            dst_transform=transform,\n",
    "            dst_crs=hls_crs,\n",
    "            resampling=Resampling.nearest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88853f0a-ebc1-4281-b66e-6e5008e9b1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2 Split the LU image into 224 x 224 patches and get corresponding HLS image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45aceb4-1515-4b3a-975b-6343b5af0acc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ESTIMATED RUNTIME: 1-2 minutes, depends on the size of the image\n",
    "\n",
    "#NOTE: the functions in this cell output a raster file for every step of the process, this is done so there is a \"checkpoint\" for every step\n",
    "# and the outputs for each process can be reviewed\n",
    "\n",
    "import os\n",
    "import math\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.windows import Window\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# function to get the bounding box of raster image\n",
    "def get_bbox(img_path):\n",
    "    with rio.open(img_path) as ref_raster:\n",
    "        bounds = ref_raster.bounds\n",
    "        bbox = box(bounds.left,\n",
    "                   bounds.bottom,\n",
    "                   bounds.right,\n",
    "                   bounds.top)\n",
    "\n",
    "    gdf = gpd.GeoDataFrame({'geometry':bbox},index=[0],crs=ref_raster.crs)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "# split image\n",
    "def split_image(img_path,export_path,outfile_prefix,tile_size=224):\n",
    "    with rio.open(img_path) as src:\n",
    "        print(\"Splitting\",img_path)\n",
    "        print(\"IMG Shape:\",src.shape)\n",
    "        print(\"Tile Size:\",tile_size)\n",
    "        \n",
    "        num_tiles_x = math.ceil(src.width/tile_size)\n",
    "        num_tiles_y = math.ceil(src.height/tile_size)\n",
    "        \n",
    "\n",
    "        tile_list = []\n",
    "        \n",
    "        for y in range(num_tiles_y ):\n",
    "            for x in range(num_tiles_x):\n",
    "                window = Window(x*tile_size, y*tile_size, tile_size, tile_size)\n",
    "                transform = rio.windows.transform(window, src.transform)\n",
    "                tile = src.read(window=window)\n",
    "    \n",
    "                # Update metadata for the tile\n",
    "                profile = src.profile\n",
    "                profile.update({'height': tile.shape[1],\n",
    "                                'width': tile.shape[2],\n",
    "                                'transform': transform})\n",
    "\n",
    "                # Save the tile as a separate image file\n",
    "                outpath = os.path.join(export_path,outfile_prefix + '_tile-{:02d}-{:02d}.tif'.format(x,y))\n",
    "                with rio.open(outpath, 'w', **profile) as ds:\n",
    "                    ds.write(tile)\n",
    "                    \n",
    "def crop_resample(img_path, bounds_gdf, output_path, tile_size=224, with_zero=True):\n",
    "    # open the source raster\n",
    "    with rio.open(img_path) as src:\n",
    "        raster_crs = src.crs\n",
    "\n",
    "        # ensure bounding box has the same crs as source raster\n",
    "        bounds_gdf = bounds_gdf.to_crs(raster_crs)\n",
    "        geom = bounds_gdf.geometry\n",
    "        crop_bounds = tuple(bounds_gdf.geometry.bounds.values[0])\n",
    "        \n",
    "        # crop the image\n",
    "        cropped_image, cropped_transform = mask(src, geom, crop=True, nodata=src.nodata)\n",
    "        \n",
    "        # update metadata for cropped image\n",
    "        cropped_meta = src.meta.copy()\n",
    "        cropped_meta.update({\n",
    "            \"height\": cropped_image.shape[1],\n",
    "            \"width\": cropped_image.shape[2],\n",
    "            \"transform\": cropped_transform\n",
    "        })\n",
    "\n",
    "    # calculate the new shape\n",
    "    new_height = tile_size\n",
    "    new_width = tile_size\n",
    "    \n",
    "    # define the resampling target array\n",
    "    resampled_image = np.empty(shape=(src.count, new_height, new_width), dtype=cropped_image.dtype)\n",
    "    \n",
    "    # Define the resampling transform\n",
    "    resampling_transform = rio.transform.from_bounds(\n",
    "        *crop_bounds,\n",
    "        new_width,\n",
    "        new_height\n",
    "    )\n",
    "    \n",
    "    # Perform the resampling\n",
    "    with rio.open(img_path) as src:\n",
    "        for i in range(1, src.count + 1):\n",
    "            rio.warp.reproject(\n",
    "                source=cropped_image[i-1],\n",
    "                destination=resampled_image[i-1],\n",
    "                src_transform=cropped_transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=resampling_transform,\n",
    "                dst_crs=src.crs,\n",
    "                resampling=Resampling.bilinear\n",
    "            )\n",
    "    \n",
    "    # update metadata for resampled image\n",
    "    resampled_meta = src.meta.copy()\n",
    "    resampled_meta.update({\n",
    "        \"height\": new_height,\n",
    "        \"width\": new_width,\n",
    "        \"transform\": resampling_transform\n",
    "    })\n",
    "    \n",
    "    # write the resampled image to the output path\n",
    "    with rio.open(output_path, 'w', **resampled_meta) as dst:\n",
    "        dst.write(resampled_image)\n",
    "\n",
    "\n",
    "# step 1: create output folders for LU and HLS patches\n",
    "lu_outpath = 'output/patch_images/lu'\n",
    "hls_outpath = 'output/patch_images/hls'\n",
    "\n",
    "if not os.path.exists(lu_outpath):\n",
    "    os.makedirs(lu_outpath)\n",
    "    print(\"{} Folder CREATED successfully.\".format(lu_outpath))\n",
    "else:\n",
    "    print(\"{} Folder ALREADY EXISTS.\".format(lu_outpath))\n",
    "    \n",
    "if not os.path.exists(hls_outpath):\n",
    "    os.makedirs(hls_outpath)\n",
    "    print(\"{} Folder CREATED successfully.\".format(hls_outpath))\n",
    "else:\n",
    "    print(\"{} Folder ALREADY EXISTS.\".format(hls_outpath))\n",
    "\n",
    "# step 2: split LU into 224 x 224 patches and locate corresponding HLS data\n",
    "split_image(lu_warped_path,\n",
    "            lu_outpath,\n",
    "           'muang-udon')\n",
    "\n",
    "lu_patch_list = [fname for fname in os.listdir(lu_outpath) if os.path.splitext(fname)[-1] == '.tif']\n",
    "#print(lu_patch_list)\n",
    "\n",
    "# iterate over the list to get the corresponding HLS patches\n",
    "shape_list = []\n",
    "vals_list = []\n",
    "patch_list = []\n",
    "status_list = []\n",
    "\n",
    "for lu_patch in lu_patch_list:\n",
    "    lu_patch_path = os.path.join(lu_outpath,lu_patch)\n",
    "    #print(lu_patch_path)\n",
    "    \n",
    "    lu_patch_bbox = get_bbox(lu_patch_path)\n",
    "    \n",
    "    # reading the lu_patch to get shape and values details\n",
    "    with rio.open(lu_patch_path) as lu_src:\n",
    "        lu_data = lu_src.read(1)\n",
    "        \n",
    "        lu_shape = lu_data.shape\n",
    "        lu_vals = set(lu_data.flatten())        \n",
    "        \n",
    "        patch_list.append(lu_patch)\n",
    "        shape_list.append(lu_shape)\n",
    "        vals_list.append(lu_vals)\n",
    "        \n",
    "    # remove LU patches that only have blank values\n",
    "    if len(lu_vals) == 1:\n",
    "        print(\"Skipping patch {} due to having only blank values\".format(lu_patch))\n",
    "        print(\"LU Patch Values:\",lu_vals)\n",
    "        status_list.append(\"Skipped + Deleted, blank values only\")\n",
    "\n",
    "        os.remove(lu_patch_path)\n",
    "        continue\n",
    "    \n",
    "    # remove LU patches that are non-square\n",
    "    elif lu_shape != (224,224):\n",
    "        print(\"Skipping patch {} due to being NOT square\".format(lu_patch))\n",
    "        print(\"LU Shape:\",lu_shape)\n",
    "        status_list.append(\"Skipped + Deleted, NOT square\")\n",
    "\n",
    "        os.remove(lu_patch_path)\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(hls_stack_path, lu_patch_bbox)\n",
    "        #hls will have the same name as lu patch since it is required for the Prithvi model\n",
    "        crop_resample(hls_stack_path,\n",
    "                      lu_patch_bbox,\n",
    "                      os.path.join(hls_outpath,lu_patch))\n",
    "        \n",
    "        status_list.append(\"Corresponding HLS patch generated\")\n",
    "        \n",
    "        \n",
    "# generate a CSV log of status and patches\n",
    "preproc_df = pd.DataFrame({'patch_name':patch_list,\n",
    "                           'shape':shape_list,\n",
    "                           'values':vals_list,\n",
    "                           'status':status_list})\n",
    "                           \n",
    "preproc_df.to_csv('output/preprocessing_details.csv')\n",
    "print(\"\\n>> Preprocessing CSV generated, sample snapshot below.\")\n",
    "print(preproc_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bce941b-b0b0-4a4a-916c-33120b6a3fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Only uncomment this cell if you need to cleanse / delete the patch_images folder and generate a new one\n",
    "\n",
    "#import shutil\n",
    "\n",
    "#dir_path = 'output/patch_images'\n",
    "#shutil.rmtree(dir_path)\n",
    "\n",
    "#print(f\"Directory {dir_path} deleted successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8d7e61-b021-4f7d-918a-a3d33466650d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3 Visualizing the HLS and LU patches for quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b226f99-d81c-421e-9334-90f533cac589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Visualizing sample HLS Patch data\n",
    "# ESTIMATED RUNTIME: <1 minute\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# lst id of the sample HLS patch to view\n",
    "sample_id = 2\n",
    "\n",
    "####### HLS #######\n",
    "hls_patches_path = 'output/patch_images/hls'\n",
    "hls_patches_path_list = glob.glob(os.path.join(hls_patches_path, \"*.tif\"))\n",
    "print(\"\\n####### HLS #######\")\n",
    "print(\"Number of HLS Patches:\",len(hls_patches_path_list))\n",
    "\n",
    "# visualizing sample HLS patch\n",
    "with rio.open(hls_patches_path_list[sample_id]) as src:\n",
    "    \n",
    "    fname = os.path.basename(hls_patches_path_list[sample_id]) # get the filename from the path\n",
    "    data = src.read()\n",
    "    \n",
    "    # checking sample image shape, crs, and resolution\n",
    "    print(\">> Image shape:\",data.shape)\n",
    "    print(\"CHECK #1: Image shape should be 18,224,224 --> 18 bands, and 224 x 224 pixels.\")\n",
    "    print(\">> Image CRS:\",src.crs)\n",
    "    print(\"CHECK #2: Image should be in the same CRS as the LU patches.\")\n",
    "    print(\">> Image Resolution:\",src.res)\n",
    "    print(\"CHECK #3: Resolution should be 30m x 30m, represented as (30,30).\")\n",
    "    print()\n",
    "    \n",
    "    # visualize the HLS file\n",
    "    rgb = src.read([4,3,2]) # change to [3,2,1] for RGB. [4,3,2] shows False Color\n",
    "    \n",
    "    # scale to 0-255 for visualization\n",
    "    scaled_rgb = np.zeros_like(rgb, dtype=np.uint8)\n",
    "\n",
    "    for i in range(3):\n",
    "        band = rgb[i]\n",
    "        min_val = np.min(band[band != 0])\n",
    "        max_val = np.max(band[band != 0])\n",
    "        scaled_rgb[i] =  ((band - min_val) / (max_val - min_val)*255).astype(np.uint8)\n",
    "    \n",
    "    scaled_rgb_new = scaled_rgb.transpose((1,2,0))\n",
    "\n",
    "    # display the RGB image\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title(fname)\n",
    "    plt.imshow(scaled_rgb_new)\n",
    "    plt.show()\n",
    "    \n",
    "####### LU #######\n",
    "lu_patches_path = 'output/patch_images/lu'\n",
    "lu_patches_path_list = glob.glob(os.path.join(lu_patches_path, \"*.tif\"))\n",
    "print(\"\\n####### LU #######\")\n",
    "print(\"Number of LU Patches:\",len(lu_patches_path_list))\n",
    "\n",
    "# visualizing sample LU patch\n",
    "with rio.open(lu_patches_path_list[sample_id]) as src:\n",
    "    \n",
    "    fname = os.path.basename(lu_patches_path_list[sample_id]) # get the filename from the path\n",
    "    data = src.read(1)\n",
    "    vals = list(set(data.flatten()))\n",
    "    \n",
    "    # checking sample image shape, crs, and resolution\n",
    "    print(\">> Image shape:\",src.read().shape)\n",
    "    print(\"CHECK #1: Image shape should be 1,224,224 --> 1 band, and 224 x 224 pixels.\")\n",
    "    print(\">> LU Categories:\",vals)\n",
    "    print(\"CHECK #2: There should only be 7 values corresponding to 6 categories + '0' values for null\")\n",
    "    print(\">> Image CRS:\",src.crs)\n",
    "    print(\"CHECK #3: Image should be in the same CRS as the HLS patches.\")\n",
    "    print(\">> Image Resolution:\",src.res)\n",
    "    print(\"CHECK #4: Resolution should be 30m x 30m, represented as (30,30).\")\n",
    "    print()\n",
    "    \n",
    "    # set legend color\n",
    "    value_to_color = {\n",
    "                        1:'red',\n",
    "                        2:'yellow',\n",
    "                        3:'green',\n",
    "                        4:'blue',\n",
    "                        5:'purple',\n",
    "                        6:'pink'}\n",
    "    \n",
    "    # create a colormap with these values\n",
    "    colors = [value_to_color.get(i,'black') for i in range(0,max(value_to_color.keys()) + 1)]\n",
    "    cmap = ListedColormap(colors)\n",
    "    \n",
    "    # display raster with the colormap\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.title(fname)\n",
    "    plt.imshow(data,cmap=cmap,interpolation='none')    \n",
    "\n",
    "    # define the raster value and corresponding land use type\n",
    "    lu_legend = {1:'Urban',\n",
    "                 2:'Agricultural',\n",
    "                 3:'Forest',\n",
    "                 4:'Water',\n",
    "                 5:'Oil Palm',\n",
    "                 6:'Para Rubber'}\n",
    "\n",
    "    legend_elements = [Patch(facecolor=color, edgecolor='black', label=lu_legend[value])\n",
    "                       for value, color in value_to_color.items()]\n",
    "    plt.legend(handles=legend_elements, title=\"Legend\", loc='upper right', bbox_to_anchor=(1.4, 1))\n",
    "\n",
    "    # show the plot\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c33bdc-239a-4fc7-afc6-fcffc9a6dfb5",
   "metadata": {},
   "source": [
    "## REMINDER: Add section to merge cloud-free images for multi-image regions like Khon-Kaen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358ecc6-41c5-4970-994d-aaaec041ab01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
