{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681fb023-16a4-491c-9cf9-327613268dfd",
   "metadata": {},
   "source": [
    "# 4.3. Enable designing improving models by machine learning\n",
    "\n",
    "*Add contents summary of this page*. Here are learning objectives for the outcome. The contents requiring advanced knowledge are labelled \"(Advanced)\" to the content names.\n",
    "\n",
    "\n",
    "- 4.3.1 Methods to improve the ML model\n",
    "    - 4.3.1.1 Feature selections\n",
    "    - 4.3.1.2 ML network modification\n",
    "    - 4.3.1.3 Hyperparameter tuning for machine learning models\n",
    "    - 4.3.1.4 Pretrain models utilization\n",
    "\n",
    "- 4.3.2 Hands-on practices on ML model improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ed756-d0f8-4880-89ca-60c3b1d3e4e9",
   "metadata": {},
   "source": [
    "## 4.3.1 Methods to improve the ML model\n",
    "\n",
    "### 4.3.1.1 Feature selections\n",
    "### (Basic) [Feature Selection Techniques in Machine Learning](https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/)\n",
    "What Is Feature Selection in Machine Learning?\n",
    "The goal of feature selection techniques in machine learning is to find the best set of features that allows one to build optimized models of studied phenomena. The techniques for feature selection in machine learning can be broadly classified into the following categories:\n",
    "\n",
    "**Supervised Techniques:** These techniques can be used for labeled data and to identify the relevant features for increasing the efficiency of supervised models like classification and regression. For Example- linear regression, decision tree, SVM, etc.\n",
    "\n",
    "**Unsupervised Techniques:** These techniques can be used for unlabeled data. For Example- K-Means Clustering, Principal Component Analysis, Hierarchical Clustering, etc.\n",
    "\n",
    "From a taxonomic point of view, these techniques are classified into filter, wrapper, embedded, and hybrid methods.\n",
    "#### Types of Feature Selection Methods in ML\n",
    "**Filter Methods:** Filter methods pick up the intrinsic properties of the features measured via univariate statistics instead of cross-validation performance. These methods are faster and less computationally expensive than wrapper methods. When dealing with high-dimensional data, it is computationally cheaper to use filter methods.\n",
    "- Information Gain\n",
    "- Chi-square Test\n",
    "- Fisherâ€™s Score\n",
    "- Correlation Coefficient\n",
    "- Variance Threshold\n",
    "- Mean Absolute Difference (MAD)\n",
    "\n",
    "**Wrapper Methods:** Wrappers require some method to search the space of all possible subsets of features, assessing their quality by learning and evaluating a classifier with that feature subset. The feature selection process is based on a specific machine learning algorithm we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion. The wrapper methods usually result in better predictive accuracy than filter methods.\n",
    "- Forward Feature Selection\n",
    "- Backward Feature Elimination\n",
    "- Exhaustive Feature Selection\n",
    "- Recursive Feature Elimination\n",
    "\n",
    "**Embedded Methods:** These methods encompass the benefits of both the wrapper and filter methods by including interactions of features but also maintaining reasonable computational costs. Embedded methods are iterative in the sense that takes care of each iteration of the model training process and carefully extract those features which contribute the most to the training for a particular iteration.\n",
    "- LASSO Regularization (L1)\n",
    "- Random Forest Importance\n",
    "\n",
    "### 4.3.1.2 ML network modification\n",
    "### (Basic) \n",
    "\n",
    "\n",
    "### 4.3.1.3 Hyperparameter tuning for machine learning models \n",
    "### (Basic) [Hyperparameter tuning for machine learning models](https://www.jeremyjordan.me/hyperparameter-tuning/)\n",
    "\n",
    "Hyperparameter Tuning\" offers a comprehensive overview of the significance and techniques for hyperparameter tuning in machine learning models. It emphasizes that selecting the right hyperparameters is crucial for enhancing model performance. The guide covers various aspects, including:\n",
    "\n",
    "- Definition and Importance: Hyperparameters are parameters set before the training process, and their correct selection can significantly improve model performance.\n",
    "- Techniques: Different techniques for tuning hyperparameters, such as grid search, random search, and Bayesian optimization, are discussed.\n",
    "- Practical Tips: The site offers practical advice on starting with a wide search space and gradually narrowing it down based on the performance of the models.\n",
    "- Examples and Tools: Various examples and tools are provided to help practitioners implement these techniques effectively in their machine learning workflows.\n",
    "\n",
    "\n",
    "### (Basic) [A Comprehensive Guide on Hyperparameter Tuning and its Techniques](https://www.analyticsvidhya.com/blog/2022/02/a-comprehensive-guide-on-hyperparameter-tuning-and-its-techniques/)\n",
    "\n",
    "Hyperparameter tuning is about tweaking and selecting the right parameters to ensure the model performs optimally. It is a key step in the machine learning workflow, requiring careful consideration and experimentation. \n",
    "\n",
    "### 4.3.1.4 Pretrain models utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bcfc29-b474-4908-a21b-de7422315294",
   "metadata": {},
   "source": [
    "## 4.3.2 Hands-on practices on ML model improvement\n",
    "\n",
    "### (Code) [Hyperparameter Tuning tutorial]()\n",
    "In this tutorial, we will learn how to select the best parameters for our models. We will learn how to use GridSearchCV from the sklearn.model_selection package to tune all the parameters.\n",
    "\n",
    "-  [Hands-on with codes for Hyperparameter Tuning tutorial](code/4.3.2Hyperparameter_Tuning_tutorial.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a852aed-31c8-4ce3-b382-74702533ad70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640cbbfd-c06e-4269-8f93-0eddf353f5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
